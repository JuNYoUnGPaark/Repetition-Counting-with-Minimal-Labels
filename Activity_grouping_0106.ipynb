{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Pe5vRC64qX",
        "outputId": "36271694-44f9-42d1-bc44-602ecd07fef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 10 subjects from /content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET...\n",
            "\n",
            "================================================================================\n",
            "Trial-level table (first 30)\n",
            "================================================================================\n",
            "     subj  act_id                  activity  gt_count  duration_sec  tempo_rps    T\n",
            " subject1       6       Waist bends forward      21.0         61.44   0.341797 3072\n",
            " subject2       6       Waist bends forward      19.0         63.48   0.299307 3174\n",
            " subject3       6       Waist bends forward      21.0         64.52   0.325480 3226\n",
            " subject4       6       Waist bends forward      20.0         66.56   0.300481 3328\n",
            " subject5       6       Waist bends forward      20.0         55.30   0.361664 2765\n",
            " subject6       6       Waist bends forward      20.0         44.04   0.454133 2202\n",
            " subject7       6       Waist bends forward      20.0         61.44   0.325521 3072\n",
            " subject8       6       Waist bends forward      21.0         43.02   0.488145 2151\n",
            " subject9       6       Waist bends forward      21.0         57.34   0.366236 2867\n",
            "subject10       6       Waist bends forward      20.0         49.16   0.406835 2458\n",
            " subject1       7 Frontal elevation of arms      20.0         61.44   0.325521 3072\n",
            " subject2       7 Frontal elevation of arms      20.0         66.56   0.300481 3328\n",
            " subject3       7 Frontal elevation of arms      20.0         67.58   0.295946 3379\n",
            " subject4       7 Frontal elevation of arms      20.0         65.54   0.305157 3277\n",
            " subject5       7 Frontal elevation of arms      20.0         57.36   0.348675 2868\n",
            " subject6       7 Frontal elevation of arms      20.0         41.98   0.476417 2099\n",
            " subject7       7 Frontal elevation of arms      20.0         55.30   0.361664 2765\n",
            " subject8       7 Frontal elevation of arms      19.0         60.42   0.314465 3021\n",
            " subject9       7 Frontal elevation of arms      19.0         57.34   0.331357 2867\n",
            "subject10       7 Frontal elevation of arms      20.0         55.30   0.361664 2765\n",
            " subject1       8             Knees bending      20.0         67.58   0.295946 3379\n",
            " subject2       8             Knees bending      21.0         68.60   0.306122 3430\n",
            " subject3       8             Knees bending      21.0         63.50   0.330709 3175\n",
            " subject4       8             Knees bending      19.0         62.46   0.304195 3123\n",
            " subject5       8             Knees bending      20.0         54.28   0.368460 2714\n",
            " subject6       8             Knees bending      20.0         46.08   0.434028 2304\n",
            " subject7       8             Knees bending      21.0         56.32   0.372869 2816\n",
            " subject8       8             Knees bending      21.0         51.20   0.410156 2560\n",
            " subject9       8             Knees bending      21.0         59.38   0.353654 2969\n",
            "subject10       8             Knees bending      21.0         57.34   0.366236 2867\n",
            "\n",
            "#Trials=60 | #Activities=6 | Missing=0\n",
            "\n",
            "================================================================================\n",
            "Activity-level summary + groups\n",
            "================================================================================\n",
            "tempo q50 (median of activity mean tempo): 0.676894 reps/sec\n",
            "count threshold (largest adjacent gap midpoint): 89.100000 reps  (gap between 20.500 and 157.700)\n",
            "\n",
            " act_id                  activity  n_trials  tempo_mean_rps  tempo_std_rps  tempo_median_rps  tempo_iqr_rps tempo_group  count_mean  count_std  count_median  count_iqr count_group\n",
            "      7 Frontal elevation of arms        10        0.342135       0.052948          0.328439       0.050932        Slow        19.8   0.421637          20.0       0.00         Low\n",
            "      8             Knees bending        10        0.354238       0.045896          0.359945       0.059498        Slow        20.5   0.707107          21.0       1.00         Low\n",
            "      6       Waist bends forward        10        0.366960       0.064093          0.351730       0.071195        Slow        20.3   0.674949          20.0       1.00         Low\n",
            "     12         Jump front & back        10        0.986828       0.049791          0.976562       0.083576        Fast        20.4   0.843274          20.0       1.00         Low\n",
            "     10                   Jogging        10        2.566732       0.065577          2.547201       0.089518        Fast       157.7   4.029061         156.5       5.50        High\n",
            "     11                   Running        10        2.685547       0.136607          2.693685       0.207520        Fast       165.0   8.393119         165.5      12.75        High\n",
            "\n",
            "Group sizes:\n",
            "tempo_group: {'Slow': 3, 'Fast': 3}\n",
            "count_group: {'Low': 4, 'High': 2}\n",
            "\n",
            "Tempo groups:\n",
            "  Slow: ['Frontal elevation of arms', 'Knees bending', 'Waist bends forward']\n",
            "  Fast: ['Jump front & back', 'Jogging', 'Running']\n",
            "\n",
            "Count-scale groups:\n",
            "  Low: ['Frontal elevation of arms', 'Knees bending', 'Waist bends forward', 'Jump front & back']\n",
            "  High: ['Jogging', 'Running']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Data Loading (from your base code)\n",
        "# ------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Loading {len(file_list)} subjects from {data_dir}...\")\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Quantification helpers\n",
        "# ------------------------------------------------------------\n",
        "def _iqr(s: pd.Series) -> float:\n",
        "    q1 = s.quantile(0.25)\n",
        "    q3 = s.quantile(0.75)\n",
        "    return float(q3 - q1)\n",
        "\n",
        "\n",
        "def find_largest_gap_threshold(values_1d: np.ndarray):\n",
        "    \"\"\"\n",
        "    Find split threshold by largest adjacent gap (bimodal-friendly).\n",
        "\n",
        "    Args:\n",
        "        values_1d: array-like of activity-level representative values (e.g., count_mean)\n",
        "\n",
        "    Returns:\n",
        "        thr: threshold float\n",
        "        v_sorted: sorted values\n",
        "        j: index of largest gap between v_sorted[j] and v_sorted[j+1]\n",
        "        gaps: all adjacent gaps (len N-1)\n",
        "    \"\"\"\n",
        "    v = np.asarray(values_1d, dtype=np.float64)\n",
        "    v_sorted = np.sort(v)\n",
        "\n",
        "    if v_sorted.size < 2:\n",
        "        return float(v_sorted[0]), v_sorted, 0, np.array([])\n",
        "\n",
        "    gaps = v_sorted[1:] - v_sorted[:-1]\n",
        "    j = int(np.argmax(gaps))\n",
        "    thr = float((v_sorted[j] + v_sorted[j + 1]) / 2.0)\n",
        "    return thr, v_sorted, j, gaps\n",
        "\n",
        "\n",
        "def compute_tempo_and_count_groups(\n",
        "    full_data,\n",
        "    all_labels,             # list of (subj, act_id, gt_count)\n",
        "    target_map,             # {act_id: act_name}\n",
        "    feature_map,            # {act_id: [feature cols]}\n",
        "    fs: float,\n",
        "    print_trials=True,\n",
        "    print_activity_table=True,\n",
        "    save_dir=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Trial tempo:\n",
        "        r_i = C_i / T_i (reps/sec), where T_i = duration_sec = len(raw_df)/fs\n",
        "    Activity tempo summary:\n",
        "        mean/std/median/IQR over r_i\n",
        "\n",
        "    Activity count summary:\n",
        "        mean/std/median/IQR over C_i\n",
        "\n",
        "    Grouping:\n",
        "      - tempo_group (Slow/Fast) by q50 of activity-level mean tempo\n",
        "      - count_group (Low/High) by \"largest adjacent gap\" threshold on activity-level mean count\n",
        "        (robust when counts are bimodal e.g., ~20 vs ~165)\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    missing = 0\n",
        "\n",
        "    # ---- trial-level rows ----\n",
        "    for subj, act_id, gt_count in all_labels:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if act_name is None or feats is None:\n",
        "            missing += 1\n",
        "            continue\n",
        "\n",
        "        if subj not in full_data or act_name not in full_data[subj]:\n",
        "            missing += 1\n",
        "            continue\n",
        "\n",
        "        raw_df = full_data[subj][act_name][feats]   # (T, C)\n",
        "        T = int(len(raw_df))\n",
        "        dur = max(T / float(fs), 1e-6)\n",
        "        r_i = float(gt_count) / dur  # reps/sec\n",
        "\n",
        "        rows.append({\n",
        "            \"subj\": subj,\n",
        "            \"act_id\": int(act_id),\n",
        "            \"activity\": act_name,\n",
        "            \"gt_count\": float(gt_count),\n",
        "            \"T\": T,\n",
        "            \"duration_sec\": dur,\n",
        "            \"tempo_rps\": r_i,\n",
        "        })\n",
        "\n",
        "    trial_df = pd.DataFrame(rows)\n",
        "    if trial_df.empty:\n",
        "        print(\"[Error] No trials collected. Check data_dir / labels / target_map.\")\n",
        "        return trial_df, pd.DataFrame(), {}\n",
        "\n",
        "    if print_trials:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Trial-level table (first 30)\")\n",
        "        print(\"=\" * 80)\n",
        "        cols = [\"subj\", \"act_id\", \"activity\", \"gt_count\", \"duration_sec\", \"tempo_rps\", \"T\"]\n",
        "        print(trial_df[cols].head(30).to_string(index=False))\n",
        "        print(f\"\\n#Trials={len(trial_df)} | #Activities={trial_df['activity'].nunique()} | Missing={missing}\")\n",
        "\n",
        "    # ---- activity-level summaries ----\n",
        "    g = trial_df.groupby([\"act_id\", \"activity\"], as_index=False)\n",
        "\n",
        "    act_df = g.agg(\n",
        "        n_trials=(\"tempo_rps\", \"count\"),\n",
        "\n",
        "        tempo_mean_rps=(\"tempo_rps\", \"mean\"),\n",
        "        tempo_std_rps=(\"tempo_rps\", \"std\"),\n",
        "        tempo_median_rps=(\"tempo_rps\", \"median\"),\n",
        "        tempo_iqr_rps=(\"tempo_rps\", _iqr),\n",
        "\n",
        "        count_mean=(\"gt_count\", \"mean\"),\n",
        "        count_std=(\"gt_count\", \"std\"),\n",
        "        count_median=(\"gt_count\", \"median\"),\n",
        "        count_iqr=(\"gt_count\", _iqr),\n",
        "    )\n",
        "\n",
        "    act_df[\"tempo_std_rps\"] = act_df[\"tempo_std_rps\"].fillna(0.0)\n",
        "    act_df[\"count_std\"] = act_df[\"count_std\"].fillna(0.0)\n",
        "\n",
        "    # ---- tempo split: q50 over activity-level mean tempo ----\n",
        "    tempo_q50 = float(act_df[\"tempo_mean_rps\"].median())\n",
        "    act_df[\"tempo_group\"] = np.where(act_df[\"tempo_mean_rps\"] <= tempo_q50, \"Slow\", \"Fast\")\n",
        "\n",
        "    # ---- count split: largest-gap threshold over activity-level mean count ----\n",
        "    count_thr, sorted_counts, gap_j, gaps = find_largest_gap_threshold(act_df[\"count_mean\"].values)\n",
        "    act_df[\"count_group\"] = np.where(act_df[\"count_mean\"] <= count_thr, \"Low\", \"High\")\n",
        "\n",
        "    # sort for readability\n",
        "    act_df = act_df.sort_values([\"tempo_mean_rps\", \"count_mean\"]).reset_index(drop=True)\n",
        "\n",
        "    thresholds = {\n",
        "        \"tempo_q50_rps\": tempo_q50,\n",
        "        \"count_thr_largest_gap\": count_thr,\n",
        "        \"count_gap_between\": (float(sorted_counts[gap_j]), float(sorted_counts[gap_j + 1])) if sorted_counts.size >= 2 else (None, None),\n",
        "    }\n",
        "\n",
        "    if print_activity_table:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Activity-level summary + groups\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"tempo q50 (median of activity mean tempo): {tempo_q50:.6f} reps/sec\")\n",
        "\n",
        "        if sorted_counts.size >= 2:\n",
        "            a = float(sorted_counts[gap_j])\n",
        "            b = float(sorted_counts[gap_j + 1])\n",
        "            print(f\"count threshold (largest adjacent gap midpoint): {count_thr:.6f} reps  \"\n",
        "                  f\"(gap between {a:.3f} and {b:.3f})\")\n",
        "        else:\n",
        "            print(f\"count threshold (largest-gap): {count_thr:.6f} reps (only one activity)\")\n",
        "\n",
        "        print()\n",
        "\n",
        "        cols = [\n",
        "            \"act_id\", \"activity\", \"n_trials\",\n",
        "            \"tempo_mean_rps\", \"tempo_std_rps\", \"tempo_median_rps\", \"tempo_iqr_rps\", \"tempo_group\",\n",
        "            \"count_mean\", \"count_std\", \"count_median\", \"count_iqr\", \"count_group\",\n",
        "        ]\n",
        "        print(act_df[cols].to_string(index=False))\n",
        "\n",
        "        print(\"\\nGroup sizes:\")\n",
        "        print(\"tempo_group:\", act_df[\"tempo_group\"].value_counts().to_dict())\n",
        "        print(\"count_group:\", act_df[\"count_group\"].value_counts().to_dict())\n",
        "\n",
        "        # optional: group membership lists\n",
        "        print(\"\\nTempo groups:\")\n",
        "        for gname in [\"Slow\", \"Fast\"]:\n",
        "            acts = act_df.loc[act_df[\"tempo_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "        print(\"\\nCount-scale groups:\")\n",
        "        for gname in [\"Low\", \"High\"]:\n",
        "            acts = act_df.loc[act_df[\"count_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "    if save_dir is not None:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        trial_path = os.path.join(save_dir, \"trial_tempo_count_table.csv\")\n",
        "        act_path = os.path.join(save_dir, \"activity_tempo_count_summary.csv\")\n",
        "        trial_df.to_csv(trial_path, index=False)\n",
        "        act_df.to_csv(act_path, index=False)\n",
        "        print(f\"\\n[Saved] {trial_path}\")\n",
        "        print(f\"[Saved] {act_path}\")\n",
        "\n",
        "    return trial_df, act_df, thresholds\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Main (only for quantification/logging)\n",
        "# ------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "        \"fs\": 50,\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            6:  'Waist bends forward',\n",
        "            7:  'Frontal elevation of arms',\n",
        "            8:  'Knees bending',\n",
        "            10: 'Jogging',\n",
        "            11: 'Running',\n",
        "            12: 'Jump front & back',\n",
        "        },\n",
        "\n",
        "        # Features: only used to select the activity segment length (T)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            6:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            7:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            8:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            10: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            11: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            12: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        \"ALL_LABELS\": [\n",
        "            (\"subject1\", 6, 21), (\"subject2\", 6, 19), (\"subject3\", 6, 21), (\"subject4\", 6, 20), (\"subject5\", 6, 20),\n",
        "            (\"subject6\", 6, 20), (\"subject7\", 6, 20), (\"subject8\", 6, 21), (\"subject9\", 6, 21), (\"subject10\", 6, 20),\n",
        "\n",
        "            (\"subject1\", 7, 20), (\"subject2\", 7, 20), (\"subject3\", 7, 20), (\"subject4\", 7, 20), (\"subject5\", 7, 20),\n",
        "            (\"subject6\", 7, 20), (\"subject7\", 7, 20), (\"subject8\", 7, 19), (\"subject9\", 7, 19), (\"subject10\", 7, 20),\n",
        "\n",
        "            (\"subject1\", 8, 20), (\"subject2\", 8, 21), (\"subject3\", 8, 21), (\"subject4\", 8, 19), (\"subject5\", 8, 20),\n",
        "            (\"subject6\", 8, 20), (\"subject7\", 8, 21), (\"subject8\", 8, 21), (\"subject9\", 8, 21), (\"subject10\", 8, 21),\n",
        "\n",
        "            (\"subject1\", 10, 157), (\"subject2\", 10, 161), (\"subject3\", 10, 154), (\"subject4\", 10, 154), (\"subject5\", 10, 160),\n",
        "            (\"subject6\", 10, 156), (\"subject7\", 10, 153), (\"subject8\", 10, 160), (\"subject9\", 10, 166), (\"subject10\", 10, 156),\n",
        "\n",
        "            (\"subject1\", 11, 165), (\"subject2\", 11, 158), (\"subject3\", 11, 174), (\"subject4\", 11, 163), (\"subject5\", 11, 157),\n",
        "            (\"subject6\", 11, 172), (\"subject7\", 11, 149), (\"subject8\", 11, 166), (\"subject9\", 11, 174), (\"subject10\", 11, 172),\n",
        "\n",
        "            (\"subject1\", 12, 20), (\"subject2\", 12, 22), (\"subject3\", 12, 21), (\"subject4\", 12, 21), (\"subject5\", 12, 20),\n",
        "            (\"subject6\", 12, 21), (\"subject7\", 12, 19), (\"subject8\", 12, 20), (\"subject9\", 12, 20), (\"subject10\", 12, 20),\n",
        "        ],\n",
        "\n",
        "        \"SAVE_DIR\": None,  # e.g., \"/content/drive/MyDrive/tempo_scale_tables\"\n",
        "    }\n",
        "\n",
        "    full_data = load_mhealth_dataset(\n",
        "        CONFIG[\"data_dir\"],\n",
        "        CONFIG[\"TARGET_ACTIVITIES_MAP\"],\n",
        "        CONFIG[\"COLUMN_NAMES\"]\n",
        "    )\n",
        "    if not full_data:\n",
        "        return\n",
        "\n",
        "    compute_tempo_and_count_groups(\n",
        "        full_data=full_data,\n",
        "        all_labels=CONFIG[\"ALL_LABELS\"],\n",
        "        target_map=CONFIG[\"TARGET_ACTIVITIES_MAP\"],\n",
        "        feature_map=CONFIG[\"ACT_FEATURE_MAP\"],\n",
        "        fs=CONFIG[\"fs\"],\n",
        "        print_trials=True,\n",
        "        print_activity_table=True,\n",
        "        save_dir=CONFIG[\"SAVE_DIR\"]\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}