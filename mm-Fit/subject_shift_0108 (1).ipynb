{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MM-Fit Trial Extractor (rebuild meta.csv + npz)  [ALL REPS]\n",
        "# - Device: sw_r (smartwatch right)\n",
        "# - Exercises: pushups, lunges, dumbbell_rows\n",
        "# - Label mapping: RELATIVE time (frame/fps) <-> IMU relative seconds\n",
        "# - Robust Drive I/O: per-session local cache copy\n",
        "# - Output: OUT_DIR/npz/*.npz + OUT_DIR/meta_*.csv\n",
        "#\n",
        "# ✅ Added:\n",
        "#   - session(w00~w20) -> participant mapping saved into meta + npz\n",
        "#   - nonfinite(X) guard: skip OR (optional) linear interpolate per channel\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, shutil, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG (EDIT)\n",
        "# -----------------------\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mm-fit\"  # mm-fit root (w00,w01,...)\n",
        "USE_DRIVE_OUTPUT = True\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials\"\n",
        "if USE_DRIVE_OUTPUT:\n",
        "    OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials\"\n",
        "\n",
        "CACHE_DIR = \"/content/mmfit_cache\"\n",
        "DEVICE = \"sw_r\"\n",
        "STREAMS = [\"acc\", \"gyr\"]\n",
        "\n",
        "TARGET_LABELS = {\"pushups\", \"lunges\", \"dumbbell_rows\"}\n",
        "ONLY_REPS = None          # ✅ ALL REPS (no filtering)\n",
        "VIDEO_FPS = 30.0\n",
        "\n",
        "TARGET_FS = 100.0         # extractor output fs\n",
        "TRIM_SEC = 0.0\n",
        "\n",
        "# nonfinite policy: \"skip\" (추천) or \"fix\"\n",
        "NONFINITE_POLICY = \"skip\"\n",
        "\n",
        "# -----------------------\n",
        "# session -> participant mapping\n",
        "# -----------------------\n",
        "WORKOUT_TO_PARTICIPANT = {\n",
        "    \"w00\": 2, \"w01\": 0, \"w02\": 1, \"w03\": 0, \"w04\": 1,\n",
        "    \"w05\": 2, \"w06\": 0, \"w07\": 1, \"w08\": 0, \"w09\": 1,\n",
        "    \"w10\": 0, \"w11\": 1, \"w12\": 3, \"w13\": 4, \"w14\": 0,\n",
        "    \"w15\": 1, \"w16\": 5, \"w17\": 6, \"w18\": 7, \"w19\": 8,\n",
        "    \"w20\": 9\n",
        "}\n",
        "\n",
        "# -----------------------\n",
        "# dirs\n",
        "# -----------------------\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "NPZ_DIR = os.path.join(OUT_DIR, \"npz\")\n",
        "os.makedirs(NPZ_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "OUT_META = os.path.join(OUT_DIR, f\"meta_{DEVICE}_{'_'.join(sorted(TARGET_LABELS))}.csv\")\n",
        "\n",
        "# -----------------------\n",
        "# helpers\n",
        "# -----------------------\n",
        "def is_gdrive_path(p: str) -> bool:\n",
        "    return p.startswith(\"/content/drive\")\n",
        "\n",
        "def list_sessions(root: str):\n",
        "    return sorted([d for d in glob.glob(os.path.join(root, \"w*\")) if os.path.isdir(d)])\n",
        "\n",
        "def np_load_safe(path: str, retries: int = 3):\n",
        "    last = None\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            return np.load(path, allow_pickle=False)\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            time.sleep(0.4)\n",
        "    raise last\n",
        "\n",
        "def read_labels_csv(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    df.columns = [\"start_frame\", \"end_frame\", \"reps\", \"exercise\"]\n",
        "    df[\"exercise\"] = df[\"exercise\"].astype(str).str.strip()\n",
        "    df[\"start_frame\"] = pd.to_numeric(df[\"start_frame\"], errors=\"coerce\")\n",
        "    df[\"end_frame\"]   = pd.to_numeric(df[\"end_frame\"],   errors=\"coerce\")\n",
        "    df[\"reps\"]        = pd.to_numeric(df[\"reps\"],        errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"start_frame\",\"end_frame\",\"reps\"])\n",
        "    df = df[df[\"end_frame\"] > df[\"start_frame\"]].copy()\n",
        "    return df\n",
        "\n",
        "def parse_imu(arr: np.ndarray):\n",
        "    # expected (N,5) = [device_id, timestamp(ms), x, y, z]\n",
        "    if arr.ndim != 2 or arr.shape[1] < 5:\n",
        "        raise ValueError(f\"Unexpected IMU shape: {arr.shape}\")\n",
        "    ts_ms = arr[:, 1].astype(np.float64)\n",
        "    xyz = arr[:, -3:].astype(np.float64)\n",
        "    return ts_ms, xyz\n",
        "\n",
        "def infer_fs(ts_ms: np.ndarray):\n",
        "    d = np.diff(ts_ms)\n",
        "    d = d[(d > 0) & np.isfinite(d)]\n",
        "    if len(d) == 0:\n",
        "        return 0.0\n",
        "    md = float(np.median(d))  # ms\n",
        "    return 1000.0 / md\n",
        "\n",
        "def safe_trim_by_seconds(s: int, e: int, trim_sec: float, fs: float, n: int):\n",
        "    if trim_sec <= 0 or fs <= 0:\n",
        "        return s, e\n",
        "    trim_n = int(round(trim_sec * fs))\n",
        "    s2 = min(max(0, s + trim_n), n - 1)\n",
        "    e2 = max(min(n, e - trim_n), s2 + 1)\n",
        "    return s2, e2\n",
        "\n",
        "def resample_to_fs(t_sec: np.ndarray, x: np.ndarray, target_fs: float):\n",
        "    if target_fs is None or target_fs <= 0:\n",
        "        return t_sec.astype(np.float32), x.astype(np.float32)\n",
        "\n",
        "    if len(t_sec) < 2:\n",
        "        return t_sec.astype(np.float32), x.astype(np.float32)\n",
        "\n",
        "    dur = float(t_sec[-1])\n",
        "    if dur <= 0:\n",
        "        return t_sec.astype(np.float32), x.astype(np.float32)\n",
        "\n",
        "    dt = 1.0 / float(target_fs)\n",
        "    t_new = np.arange(0.0, dur + 1e-9, dt)\n",
        "    if len(t_new) < 2:\n",
        "        return t_sec.astype(np.float32), x.astype(np.float32)\n",
        "\n",
        "    f = interp1d(t_sec, x, axis=0, kind=\"linear\",\n",
        "                 fill_value=\"extrapolate\", bounds_error=False)\n",
        "    x_new = f(t_new).astype(np.float32)\n",
        "    return t_new.astype(np.float32), x_new\n",
        "\n",
        "def ensure_cached_session(sid: str):\n",
        "    src_dir = os.path.join(DATA_ROOT, sid)\n",
        "    if not os.path.isdir(src_dir):\n",
        "        raise FileNotFoundError(f\"Session dir not found: {src_dir}\")\n",
        "\n",
        "    if not is_gdrive_path(src_dir):\n",
        "        return src_dir\n",
        "\n",
        "    dst_dir = os.path.join(CACHE_DIR, sid)\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "    need = [f\"{sid}_labels.csv\"] + [f\"{sid}_{DEVICE}_{st}.npy\" for st in STREAMS]\n",
        "    for fn in need:\n",
        "        src = os.path.join(src_dir, fn)\n",
        "        dst = os.path.join(dst_dir, fn)\n",
        "        if not os.path.exists(src):\n",
        "            continue\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy2(src, dst)\n",
        "    return dst_dir\n",
        "\n",
        "def is_finite(X: np.ndarray) -> bool:\n",
        "    return np.isfinite(X).all()\n",
        "\n",
        "def fix_nonfinite_linear(X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    X(T,C)에서 NaN/Inf가 있으면 time 축 기준으로 채널별 선형 보간.\n",
        "    양 끝은 nearest처럼 채움.\n",
        "    \"\"\"\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "    T, C = X.shape\n",
        "    t = np.arange(T, dtype=np.float64)\n",
        "    X2 = X.copy()\n",
        "\n",
        "    for c in range(C):\n",
        "        y = X2[:, c]\n",
        "        m = np.isfinite(y)\n",
        "        if m.all():\n",
        "            continue\n",
        "        if m.sum() < 2:\n",
        "            # 유효 값 거의 없으면 0으로\n",
        "            y[:] = 0.0\n",
        "            X2[:, c] = y\n",
        "            continue\n",
        "        y_interp = np.interp(t, t[m], y[m])\n",
        "        X2[:, c] = y_interp\n",
        "\n",
        "    return X2.astype(np.float32)\n",
        "\n",
        "# -----------------------\n",
        "# main extraction\n",
        "# -----------------------\n",
        "sessions = [os.path.basename(d) for d in list_sessions(DATA_ROOT)]\n",
        "print(f\"Found {len(sessions)} sessions under: {DATA_ROOT}\")\n",
        "\n",
        "records = []\n",
        "bad = []\n",
        "skipped_trials = []\n",
        "\n",
        "for sid in sessions:\n",
        "    try:\n",
        "        work_dir = ensure_cached_session(sid)\n",
        "\n",
        "        label_path = os.path.join(work_dir, f\"{sid}_labels.csv\")\n",
        "        acc_path   = os.path.join(work_dir, f\"{sid}_{DEVICE}_acc.npy\")\n",
        "        gyr_path   = os.path.join(work_dir, f\"{sid}_{DEVICE}_gyr.npy\")\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            bad.append((sid, \"no_labels\"))\n",
        "            continue\n",
        "        if not os.path.exists(acc_path) or not os.path.exists(gyr_path):\n",
        "            bad.append((sid, \"missing_acc_or_gyr\"))\n",
        "            continue\n",
        "\n",
        "        participant = WORKOUT_TO_PARTICIPANT.get(sid, None)\n",
        "        if participant is None:\n",
        "            bad.append((sid, \"no_participant_mapping\"))\n",
        "            continue\n",
        "\n",
        "        lab = read_labels_csv(label_path)\n",
        "        lab = lab[lab[\"exercise\"].isin(TARGET_LABELS)].copy()\n",
        "\n",
        "        if ONLY_REPS is not None:\n",
        "            lab = lab[lab[\"reps\"].round().astype(int) == int(ONLY_REPS)].copy()\n",
        "\n",
        "        if len(lab) == 0:\n",
        "            continue\n",
        "\n",
        "        ts_a, acc_all = parse_imu(np_load_safe(acc_path))\n",
        "        ts_g, gyr_all = parse_imu(np_load_safe(gyr_path))\n",
        "\n",
        "        t_rel_a = (ts_a - ts_a[0]) / 1000.0\n",
        "        t_rel_g = (ts_g - ts_g[0]) / 1000.0\n",
        "\n",
        "        fs_a = infer_fs(ts_a)\n",
        "        fs_g = infer_fs(ts_g)\n",
        "        fs_native = float(np.nanmean([fs_a, fs_g]))\n",
        "\n",
        "        lab = lab.sort_values(\"start_frame\").reset_index(drop=True)\n",
        "        print(f\"\\n[{sid}] participant={participant} | sets={len(lab)} | fs_native~{fs_native:.2f}Hz\")\n",
        "\n",
        "        for set_id, r in lab.iterrows():\n",
        "            sf = float(r[\"start_frame\"])\n",
        "            ef = float(r[\"end_frame\"])\n",
        "            reps = float(r[\"reps\"])\n",
        "            ex = str(r[\"exercise\"]).strip()\n",
        "\n",
        "            t0 = sf / VIDEO_FPS\n",
        "            t1 = ef / VIDEO_FPS\n",
        "            if t1 <= t0:\n",
        "                continue\n",
        "\n",
        "            s_a = int(np.searchsorted(t_rel_a, t0, side=\"left\"))\n",
        "            e_a = int(np.searchsorted(t_rel_a, t1, side=\"left\"))\n",
        "            s_g = int(np.searchsorted(t_rel_g, t0, side=\"left\"))\n",
        "            e_g = int(np.searchsorted(t_rel_g, t1, side=\"left\"))\n",
        "\n",
        "            n_a, n_g = len(t_rel_a), len(t_rel_g)\n",
        "            s_a = max(0, min(n_a - 1, s_a)); e_a = max(s_a + 1, min(n_a, e_a))\n",
        "            s_g = max(0, min(n_g - 1, s_g)); e_g = max(s_g + 1, min(n_g, e_g))\n",
        "\n",
        "            s_a, e_a = safe_trim_by_seconds(s_a, e_a, TRIM_SEC, fs_a, n_a)\n",
        "            s_g, e_g = safe_trim_by_seconds(s_g, e_g, TRIM_SEC, fs_g, n_g)\n",
        "\n",
        "            acc_seg = acc_all[s_a:e_a].astype(np.float32)\n",
        "            gyr_seg = gyr_all[s_g:e_g].astype(np.float32)\n",
        "\n",
        "            t_seg = t_rel_a[s_a:e_a]\n",
        "            t_seg = (t_seg - t_seg[0]).astype(np.float32)\n",
        "\n",
        "            T = min(len(acc_seg), len(gyr_seg), len(t_seg))\n",
        "            if T < 8:\n",
        "                continue\n",
        "            acc_seg = acc_seg[:T]\n",
        "            gyr_seg = gyr_seg[:T]\n",
        "            t_seg = t_seg[:T]\n",
        "\n",
        "            X = np.concatenate([acc_seg, gyr_seg], axis=1).astype(np.float32)  # (T,6)\n",
        "\n",
        "            # nonfinite guard (before resample)\n",
        "            if not is_finite(X):\n",
        "                if NONFINITE_POLICY == \"fix\":\n",
        "                    X = fix_nonfinite_linear(X)\n",
        "                else:\n",
        "                    skipped_trials.append((sid, set_id, ex, \"nonfinite_before_resample\"))\n",
        "                    continue\n",
        "            if not is_finite(X):\n",
        "                skipped_trials.append((sid, set_id, ex, \"still_nonfinite_before_resample\"))\n",
        "                continue\n",
        "\n",
        "            # resample to TARGET_FS\n",
        "            t_rs, X_rs = resample_to_fs(t_seg, X, TARGET_FS)\n",
        "            fs_out = float(TARGET_FS)\n",
        "\n",
        "            # nonfinite guard (after resample)\n",
        "            if not is_finite(X_rs):\n",
        "                if NONFINITE_POLICY == \"fix\":\n",
        "                    X_rs = fix_nonfinite_linear(X_rs)\n",
        "                else:\n",
        "                    skipped_trials.append((sid, set_id, ex, \"nonfinite_after_resample\"))\n",
        "                    continue\n",
        "            if not is_finite(X_rs):\n",
        "                skipped_trials.append((sid, set_id, ex, \"still_nonfinite_after_resample\"))\n",
        "                continue\n",
        "\n",
        "            out_name = f\"{sid}_set{set_id:03d}_{ex}_reps{int(round(reps))}.npz\"\n",
        "            out_path = os.path.join(NPZ_DIR, out_name)\n",
        "\n",
        "            np.savez_compressed(\n",
        "                out_path,\n",
        "                X=X_rs,\n",
        "                t=t_rs,\n",
        "                session=sid,\n",
        "                participant=int(participant),   # ✅ added\n",
        "                set_id=int(set_id),\n",
        "                exercise=ex,\n",
        "                reps=float(reps),\n",
        "                start_frame=float(sf),\n",
        "                end_frame=float(ef),\n",
        "                fs=float(fs_out),\n",
        "                fs_native=float(fs_native),\n",
        "                device=DEVICE\n",
        "            )\n",
        "\n",
        "            records.append({\n",
        "                \"session\": sid,\n",
        "                \"participant\": int(participant),  # ✅ added\n",
        "                \"set_id\": int(set_id),\n",
        "                \"exercise\": ex,\n",
        "                \"reps\": float(reps),\n",
        "                \"start_frame\": float(sf),\n",
        "                \"end_frame\": float(ef),\n",
        "                \"T\": int(len(t_rs)),\n",
        "                \"dur_sec\": float(t_rs[-1]) if len(t_rs) > 1 else 0.0,\n",
        "                \"fs\": float(fs_out),\n",
        "                \"fs_native\": float(fs_native),\n",
        "                \"device\": DEVICE,\n",
        "                \"npz_path\": out_path,\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        bad.append((sid, f\"error:{repr(e)[:160]}\"))\n",
        "        continue\n",
        "\n",
        "meta = pd.DataFrame(records)\n",
        "\n",
        "print(\"\\n--- DONE ---\")\n",
        "print(\"Bad sessions (first 20):\", bad[:20])\n",
        "print(\"Skipped trials (first 20):\", skipped_trials[:20])\n",
        "print(\"Total trials saved:\", len(meta))\n",
        "\n",
        "if len(meta) > 0:\n",
        "    meta.to_csv(OUT_META, index=False)\n",
        "    print(\"Meta CSV:\", OUT_META)\n",
        "    print(\"NPZ dir:\", NPZ_DIR)\n",
        "    print(\"\\nCounts by exercise:\")\n",
        "    print(meta[\"exercise\"].value_counts())\n",
        "    print(\"\\nParticipants count:\")\n",
        "    print(meta[\"participant\"].value_counts().sort_index())\n",
        "else:\n",
        "    print(\"[WARN] No trials extracted. Check paths / device availability / mapping.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CNApgKnmgGq",
        "outputId": "97c84d8e-bdb8-4615-d4e3-7faa27922644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21 sessions under: /content/drive/MyDrive/Colab Notebooks/HAR_data/mm-fit\n",
            "\n",
            "[w00] participant=2 | sets=9 | fs_native~100.00Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/interpolate/_interpolate.py:497: RuntimeWarning: divide by zero encountered in divide\n",
            "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/interpolate/_interpolate.py:500: RuntimeWarning: invalid value encountered in multiply\n",
            "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[w01] participant=0 | sets=10 | fs_native~100.00Hz\n",
            "\n",
            "[w02] participant=1 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w03] participant=0 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w04] participant=1 | sets=8 | fs_native~100.00Hz\n",
            "\n",
            "[w05] participant=2 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w06] participant=0 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w07] participant=1 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w08] participant=0 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w09] participant=1 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w10] participant=0 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w11] participant=1 | sets=9 | fs_native~100.00Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/interpolate/_interpolate.py:497: RuntimeWarning: divide by zero encountered in divide\n",
            "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/interpolate/_interpolate.py:500: RuntimeWarning: invalid value encountered in multiply\n",
            "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[w12] participant=3 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w13] participant=4 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w14] participant=0 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w15] participant=1 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "[w16] participant=5 | sets=10 | fs_native~100.00Hz\n",
            "\n",
            "[w17] participant=6 | sets=10 | fs_native~100.00Hz\n",
            "\n",
            "[w18] participant=7 | sets=9 | fs_native~105.56Hz\n",
            "\n",
            "[w19] participant=8 | sets=9 | fs_native~105.56Hz\n",
            "\n",
            "[w20] participant=9 | sets=9 | fs_native~100.00Hz\n",
            "\n",
            "--- DONE ---\n",
            "Bad sessions (first 20): []\n",
            "Skipped trials (first 20): [('w00', 0, 'pushups', 'nonfinite_after_resample'), ('w11', 6, 'dumbbell_rows', 'nonfinite_after_resample')]\n",
            "Total trials saved: 189\n",
            "Meta CSV: /content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials/meta_sw_r_dumbbell_rows_lunges_pushups.csv\n",
            "NPZ dir: /content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials/npz\n",
            "\n",
            "Counts by exercise:\n",
            "exercise\n",
            "pushups          64\n",
            "dumbbell_rows    63\n",
            "lunges           62\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Participants count:\n",
            "participant\n",
            "0    55\n",
            "1    52\n",
            "2    17\n",
            "3     9\n",
            "4     9\n",
            "5    10\n",
            "6    10\n",
            "7     9\n",
            "8     9\n",
            "9     9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Count-only K-auto (Multi-event) + Windowing version  (MM-Fit drop-in)\n",
        "#\n",
        "# ✅ This version (UPDATED for new data):\n",
        "#   1) Activity-specific LOSO (single-activity subject shift)  ✅ subject = participant\n",
        "#   2) Skip non-finite trials (NaN/Inf) at loading stage       ✅ skip only\n",
        "#   3) Logs formatted per your template (per activity)\n",
        "#\n",
        "# ✅ Only changed parts:\n",
        "#   - [THIS PATCH] Fold TEST Summary now aggregates across ALL trials of the test subject\n",
        "#                 (mean±std for GT/Pred/Diff/k_hat/entropy + n_trials)\n",
        "#                 ❗Everything else unchanged.\n",
        "#\n",
        "# (Model / Loss / Train / Windowing / Inference / Viz are UNCHANGED)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading  (MM-Fit)  ✅ UPDATED: requires participant\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mmfit_meta(meta_csv_path: str,\n",
        "                    target_exercises: set,\n",
        "                    only_reps=None,\n",
        "                    require_device: str = \"sw_r\"):\n",
        "    \"\"\"\n",
        "    meta.csv 로딩.\n",
        "    ✅ NEW DATA expected columns:\n",
        "      participant, session, set_id, exercise, reps, fs, npz_path\n",
        "    \"\"\"\n",
        "    if not os.path.exists(meta_csv_path):\n",
        "        raise FileNotFoundError(f\"[MM-Fit] meta csv not found: {meta_csv_path}\")\n",
        "\n",
        "    meta = pd.read_csv(meta_csv_path)\n",
        "\n",
        "    # ✅ participant required\n",
        "    need_cols = [\"participant\", \"session\", \"set_id\", \"exercise\", \"reps\", \"fs\", \"npz_path\"]\n",
        "    for c in need_cols:\n",
        "        if c not in meta.columns:\n",
        "            raise ValueError(f\"[MM-Fit] meta csv missing column: {c} (have={list(meta.columns)})\")\n",
        "\n",
        "    meta[\"exercise\"] = meta[\"exercise\"].astype(str).str.strip()\n",
        "    meta[\"session\"] = meta[\"session\"].astype(str).str.strip()\n",
        "\n",
        "    # participant sanitize\n",
        "    meta[\"participant\"] = pd.to_numeric(meta[\"participant\"], errors=\"coerce\")\n",
        "    meta = meta.dropna(subset=[\"participant\"]).copy()\n",
        "    meta[\"participant\"] = meta[\"participant\"].astype(int)\n",
        "\n",
        "    # device 필터 (device 컬럼 있을 때만)\n",
        "    if \"device\" in meta.columns and require_device is not None:\n",
        "        meta = meta[meta[\"device\"].astype(str).str.strip() == require_device].copy()\n",
        "\n",
        "    # exercise 필터\n",
        "    meta = meta[meta[\"exercise\"].isin(set(target_exercises))].copy()\n",
        "\n",
        "    # reps 필터 (원하면)\n",
        "    if only_reps is not None:\n",
        "        meta = meta[meta[\"reps\"].round().astype(int) == int(only_reps)].copy()\n",
        "\n",
        "    # npz_path 존재 확인\n",
        "    meta[\"npz_path\"] = meta[\"npz_path\"].astype(str)\n",
        "    ok = meta[\"npz_path\"].apply(lambda p: os.path.exists(p))\n",
        "    meta = meta[ok].copy()\n",
        "\n",
        "    meta = meta.sort_values([\"participant\", \"session\", \"exercise\", \"set_id\"]).reset_index(drop=True)\n",
        "    return meta\n",
        "\n",
        "\n",
        "def _is_finite_np(x: np.ndarray) -> bool:\n",
        "    return np.isfinite(x).all()\n",
        "\n",
        "\n",
        "def prepare_trial_list_mmfit(meta_rows: pd.DataFrame,\n",
        "                            expected_fs: float,\n",
        "                            skip_nonfinite: bool = True,\n",
        "                            verbose_skip: bool = True):\n",
        "    \"\"\"\n",
        "    - 각 row = 1 trial\n",
        "    - count label = reps\n",
        "    - per-trial z-score\n",
        "    - ✅ nonfinite(X에 NaN/Inf)면 스킵 (skip only)\n",
        "    \"\"\"\n",
        "    trial_list = []\n",
        "    skipped = []  # (reason, npz_path)\n",
        "\n",
        "    for _, r in meta_rows.iterrows():\n",
        "        npz_path = str(r[\"npz_path\"])\n",
        "        try:\n",
        "            d = np.load(npz_path, allow_pickle=True)\n",
        "        except Exception:\n",
        "            skipped.append((\"npz_load_fail\", npz_path))\n",
        "            continue\n",
        "\n",
        "        if \"X\" not in d.files:\n",
        "            skipped.append((\"missing_X\", npz_path))\n",
        "            continue\n",
        "\n",
        "        X = d[\"X\"].astype(np.float32)  # (T,C)\n",
        "        reps = float(r[\"reps\"])\n",
        "        sid = str(r[\"session\"])\n",
        "        pid = int(r[\"participant\"])\n",
        "        set_id = int(r[\"set_id\"])\n",
        "        ex = str(r[\"exercise\"])\n",
        "\n",
        "        # fs check\n",
        "        try:\n",
        "            fs_npz = float(d[\"fs\"]) if \"fs\" in d.files else float(r[\"fs\"])\n",
        "        except Exception:\n",
        "            fs_npz = float(r[\"fs\"])\n",
        "\n",
        "        if abs(fs_npz - float(expected_fs)) > 1e-3:\n",
        "            raise ValueError(\n",
        "                f\"[MM-Fit] fs mismatch for {npz_path}: fs_npz={fs_npz}, expected_fs={expected_fs}. \"\n",
        "                f\"-> extractor 단계에서 TARGET_FS를 expected_fs로 통일하세요.\"\n",
        "            )\n",
        "\n",
        "        # ✅ skip nonfinite raw X\n",
        "        if skip_nonfinite and (not _is_finite_np(X)):\n",
        "            skipped.append((\"nonfinite_X\", npz_path))\n",
        "            continue\n",
        "\n",
        "        # per-trial z-score\n",
        "        mean = X.mean(axis=0)\n",
        "        std = X.std(axis=0)\n",
        "        std = np.where(std < 1e-6, 1e-6, std).astype(np.float32)\n",
        "        norm_np = (X - mean) / std\n",
        "\n",
        "        # ✅ (안전) 정규화 후에도 nonfinite면 스킵\n",
        "        if skip_nonfinite and (not _is_finite_np(norm_np)):\n",
        "            skipped.append((\"nonfinite_after_norm\", npz_path))\n",
        "            continue\n",
        "\n",
        "        trial_list.append({\n",
        "            \"data\": norm_np,              # (T,C)\n",
        "            \"count\": float(reps),         # trial total count\n",
        "            \"meta\": f\"subj{pid}_{sid}_set{set_id:02d}_{ex}\",\n",
        "            \"participant\": pid,\n",
        "            \"session\": sid,\n",
        "            \"exercise\": ex,\n",
        "            \"npz_path\": npz_path,\n",
        "        })\n",
        "\n",
        "    if verbose_skip and len(skipped) > 0:\n",
        "        print(f\"[MM-Fit] Skipped {len(skipped)} trials (nonfinite/load issues). Examples:\")\n",
        "        for i in range(min(5, len(skipped))):\n",
        "            print(\"  -\", skipped[i][0], \":\", skipped[i][1])\n",
        "\n",
        "    return trial_list, skipped\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.5) ✅ Windowing (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True):\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C)\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        if T < win_len:\n",
        "            win_dur = T / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x,\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[0:{T}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": 0,\n",
        "                \"win_end\": T,\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        last_start = T - win_len\n",
        "        starts = list(range(0, last_start + 1, stride))\n",
        "\n",
        "        for st in starts:\n",
        "            ed = st + win_len\n",
        "            win_dur = win_len / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": st,\n",
        "                \"win_end\": ed,\n",
        "            })\n",
        "\n",
        "        if not drop_last:\n",
        "            last_st = starts[-1] + stride\n",
        "            if last_st < T:\n",
        "                ed = T\n",
        "                win_dur = (ed - last_st) / float(fs)\n",
        "                windows.append({\n",
        "                    \"data\": x[last_st:ed],\n",
        "                    \"count\": rate_trial * win_dur,\n",
        "                    \"meta\": f\"{meta}__win[{last_st}:{ed}]\",\n",
        "                    \"parent_meta\": meta,\n",
        "                    \"parent_T\": T,\n",
        "                    \"win_start\": last_st,\n",
        "                    \"win_end\": ed,\n",
        "                })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)  # (1,C,T)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        pred_count = float(rate_hat.item() * total_dur)\n",
        "        return pred_count, np.array([float(rate_hat.item())], dtype=np.float32)\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N, win_len, C)\n",
        "\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N, C, win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)  # (B,)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)  # (N,)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count), rates\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.8) Dataset / Collate (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item['data'], dtype=torch.float32).transpose(0, 1)  # (C, T)\n",
        "        count = torch.tensor(item['count'], dtype=torch.float32)\n",
        "        return data, count, item['meta']\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, metas, lengths = [], [], [], [], []\n",
        "    for data, count, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),         # (B, C, T_max)\n",
        "        \"mask\": torch.stack(masks),               # (B, T_max)\n",
        "        \"count\": torch.stack(counts),             # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Model (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)            # (B, D, T)\n",
        "        z = z.transpose(1, 2)      # (B, T, D)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)     # (B, D, T)\n",
        "        x_hat = self.net(zt)       # (B, C, T)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)  # [amp_logit | phase_logits...]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)                     # (B,T,1+K)\n",
        "        amp = F.softplus(out[..., 0])         # (B,T) >=0\n",
        "        phase_logits = out[..., 1:]           # (B,T,K)\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1)  # (B,T,K), sum=1\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6, k_hidden=64):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)  # amp logit bias만 -2\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)              # (B,T,D)\n",
        "        x_hat = self.decoder(z)          # (B,C,T)\n",
        "\n",
        "        amp_t, phase_p, phase_logits = self.rate_head(z, tau=tau)\n",
        "        rates_k_t = amp_t.unsqueeze(-1) * phase_p  # (B,T,K)\n",
        "\n",
        "        micro_rate_t = amp_t  # (B,T)\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)           # (B,K)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)          # (B,) in [1,K]\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6) # (B,T)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"rates_k_t\": rates_k_t,\n",
        "            \"phase_p\": phase_p,\n",
        "            \"phase_logits\": phase_logits,\n",
        "            \"micro_rate_t\": micro_rate_t,\n",
        "            \"rep_rate_t\": rep_rate_t,\n",
        "            \"k_hat\": k_hat,\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Loss utils (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)              # (B,1,T)\n",
        "    se = (x_hat - x) ** 2                    # (B,C,T)\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps  # valid(B*T)*C\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])  # (B,T-1)\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)  # (B,T)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)  # (B,K)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)  # (B,T,1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean(), effK.detach()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Train (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "    stats = {k: 0.0 for k in [\n",
        "        'loss', 'loss_rate', 'loss_recon', 'loss_smooth', 'loss_phase_ent', 'loss_effk',\n",
        "        'mae_count'\n",
        "    ]}\n",
        "\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.005)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)         # (B,C,T)\n",
        "        mask = batch[\"mask\"].to(device)      # (B,T)\n",
        "        y_count = batch[\"count\"].to(device)  # (B,)\n",
        "        length = batch[\"length\"].to(device)  # (B,)\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)  # sec\n",
        "        y_rate = y_count / duration                    # reps/s\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rate_hat, z, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = F.mse_loss(rate_hat, y_rate)\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk, _ = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        count_hat = rate_hat * duration\n",
        "        stats['loss'] += loss.item()\n",
        "        stats['loss_rate'] += loss_rate.item()\n",
        "        stats['loss_recon'] += loss_recon.item()\n",
        "        stats['loss_smooth'] += loss_smooth.item()\n",
        "        stats['loss_phase_ent'] += loss_phase_ent.item()\n",
        "        stats['loss_effk'] += loss_effk.item()\n",
        "        stats['mae_count'] += torch.abs(count_hat - y_count).mean().item()\n",
        "\n",
        "    n = max(1, len(loader))\n",
        "    return {k: v / n for k, v in stats.items()}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Visualization helpers (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "def compute_phase_entropy_mean(phase_p_np, eps=1e-8):\n",
        "    phase_p_np = np.asarray(phase_p_np, dtype=np.float32)\n",
        "    ent_t = -(phase_p_np * np.log(phase_p_np + eps)).sum(axis=1)  # (T,)\n",
        "    return float(ent_t.mean())\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7) LOSO runner (per activity)  ✅ UPDATED: subject = participant\n",
        "# ---------------------------------------------------------------------\n",
        "def run_loso_for_one_activity(meta_all: pd.DataFrame, activity: str, CONFIG: dict, device):\n",
        "    meta_act = meta_all[meta_all[\"exercise\"] == activity].copy()\n",
        "    if len(meta_act) == 0:\n",
        "        print(f\"[WARN] No trials for activity={activity}\")\n",
        "        return None\n",
        "\n",
        "    # ✅ subject shift 기준: participant\n",
        "    subjects = sorted(meta_act[\"participant\"].unique().tolist())\n",
        "\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(f\" >>> Starting LOSO (count-only, K-auto) + WINDOWING\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    loso_results = []\n",
        "    total_skipped = 0\n",
        "\n",
        "    for fold_idx, test_subj in enumerate(subjects):\n",
        "        set_strict_seed(CONFIG[\"seed\"])\n",
        "\n",
        "        train_meta = meta_act[meta_act[\"participant\"] != test_subj].copy()\n",
        "        test_meta  = meta_act[meta_act[\"participant\"] == test_subj].copy()\n",
        "\n",
        "        train_trials, skipped_train = prepare_trial_list_mmfit(\n",
        "            train_meta, expected_fs=CONFIG[\"fs\"],\n",
        "            skip_nonfinite=True, verbose_skip=False\n",
        "        )\n",
        "        test_trials, skipped_test = prepare_trial_list_mmfit(\n",
        "            test_meta, expected_fs=CONFIG[\"fs\"],\n",
        "            skip_nonfinite=True, verbose_skip=False\n",
        "        )\n",
        "        total_skipped += (len(skipped_train) + len(skipped_test))\n",
        "\n",
        "        if len(train_trials) == 0 or len(test_trials) == 0:\n",
        "            print(f\"Fold {fold_idx+1:2d} | Test: subject{test_subj} | [SKIP] no valid trials after filtering (nonfinite/empty).\")\n",
        "            continue\n",
        "\n",
        "        train_data = trial_list_to_windows(\n",
        "            train_trials,\n",
        "            fs=CONFIG[\"fs\"],\n",
        "            win_sec=CONFIG[\"win_sec\"],\n",
        "            stride_sec=CONFIG[\"stride_sec\"],\n",
        "            drop_last=CONFIG[\"drop_last\"]\n",
        "        )\n",
        "\n",
        "        if len(train_data) == 0:\n",
        "            print(f\"Fold {fold_idx+1:2d} | Test: subject{test_subj} | [SKIP] no windows generated.\")\n",
        "            continue\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            TrialDataset(train_data),\n",
        "            batch_size=CONFIG[\"batch_size\"],\n",
        "            shuffle=True,\n",
        "            collate_fn=collate_variable_length,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "        input_ch = train_data[0][\"data\"].shape[1]\n",
        "        model = KAutoCountModel(\n",
        "            input_ch=input_ch,\n",
        "            hidden_dim=CONFIG[\"hidden_dim\"],\n",
        "            latent_dim=CONFIG[\"latent_dim\"],\n",
        "            K_max=CONFIG[\"K_max\"]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "        for _ in range(CONFIG[\"epochs\"]):\n",
        "            _ = train_one_epoch(model, train_loader, optimizer, CONFIG, device)\n",
        "            scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        fold_abs_err_sum = 0.0\n",
        "        fold_res_str = \"\"\n",
        "\n",
        "        # =========================\n",
        "        # ✅ PATCH: aggregate per-trial stats for Fold TEST Summary\n",
        "        # =========================\n",
        "        gt_list, pred_list, diff_list = [], [], []\n",
        "        khat_list, ent_list = [], []\n",
        "\n",
        "        for item in test_trials:\n",
        "            x_np = item[\"data\"]\n",
        "\n",
        "            count_pred_win, _ = predict_count_by_windowing(\n",
        "                model,\n",
        "                x_np=x_np,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                device=device,\n",
        "                tau=CONFIG.get(\"tau\", 1.0),\n",
        "                batch_size=CONFIG.get(\"batch_size\", 64)\n",
        "            )\n",
        "\n",
        "            count_gt = float(item[\"count\"])\n",
        "            abs_err = abs(count_pred_win - count_gt)\n",
        "            fold_abs_err_sum += abs_err\n",
        "            fold_res_str += f\"[Pred(win): {count_pred_win:.1f} / GT: {count_gt:.0f}]\"\n",
        "\n",
        "            x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)  # (1,C,T)\n",
        "            with torch.no_grad():\n",
        "                _, _, _, aux = model(x_tensor, mask=None, tau=CONFIG.get(\"tau\", 1.0))\n",
        "\n",
        "            phase_p = aux[\"phase_p\"].squeeze(0).detach().cpu().numpy()  # (T,K)\n",
        "            k_hat = float(aux[\"k_hat\"].item())\n",
        "            ent = compute_phase_entropy_mean(phase_p)\n",
        "\n",
        "            gt_list.append(count_gt)\n",
        "            pred_list.append(float(count_pred_win))\n",
        "            diff_list.append(float(count_pred_win - count_gt))\n",
        "            khat_list.append(float(k_hat))\n",
        "            ent_list.append(float(ent))\n",
        "\n",
        "        fold_mae = fold_abs_err_sum / max(1, len(test_trials))\n",
        "        loso_results.append(fold_mae)\n",
        "\n",
        "        # ✅ 요청한 로그 포맷 (subject{participant_id})\n",
        "        print(f\"Fold {fold_idx+1:2d} | Test: subject{test_subj} | MAE: {fold_mae:.2f} | {fold_res_str}\")\n",
        "\n",
        "        if len(gt_list) > 0:\n",
        "            gt_m, gt_s     = float(np.mean(gt_list)),   float(np.std(gt_list))\n",
        "            pred_m, pred_s = float(np.mean(pred_list)), float(np.std(pred_list))\n",
        "            diff_m, diff_s = float(np.mean(diff_list)), float(np.std(diff_list))\n",
        "            k_m, k_s       = float(np.mean(khat_list)), float(np.std(khat_list))\n",
        "            e_m, e_s       = float(np.mean(ent_list)),  float(np.std(ent_list))\n",
        "\n",
        "            print(\n",
        "                f\"[Fold TEST Summary] subject{test_subj} | \"\n",
        "                f\"GT={gt_m:.2f}±{gt_s:.2f} | Pred(win)={pred_m:.2f}±{pred_s:.2f} | \"\n",
        "                f\"Diff={diff_m:+.2f}±{diff_s:.2f} | k_hat(full)={k_m:.2f}±{k_s:.2f} | \"\n",
        "                f\"phase_entropy(full)={e_m:.3f}±{e_s:.3f} | n_trials={len(gt_list)}\"\n",
        "            )\n",
        "\n",
        "    if len(loso_results) == 0:\n",
        "        print(\"-\"*80)\n",
        "        print(\" >>> No valid folds were evaluated.\")\n",
        "        print(\"-\"*80)\n",
        "        return None\n",
        "\n",
        "    print(\"-\"*80)\n",
        "    print(f\" >>> Final LOSO Result (Average MAE): {np.mean(loso_results):.3f}\")\n",
        "    print(f\" >>> Standard Deviation: {np.std(loso_results):.3f}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    return {\n",
        "        \"activity\": activity,\n",
        "        \"mean_mae\": float(np.mean(loso_results)),\n",
        "        \"std_mae\": float(np.std(loso_results)),\n",
        "        \"n_folds\": int(len(loso_results)),\n",
        "        \"total_skipped\": int(total_skipped),\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8) Main\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "\n",
        "        # MM-Fit meta.csv 경로 (✅ NEW DATA: must include participant)\n",
        "        \"mmfit_meta_csv\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials/meta_sw_r_dumbbell_rows_lunges_pushups.csv\",\n",
        "\n",
        "        \"MMFIT_TARGET_EXERCISES\": {\"pushups\", \"lunges\", \"dumbbell_rows\"},\n",
        "        \"MMFIT_ONLY_REPS\": None,\n",
        "        \"MMFIT_REQUIRE_DEVICE\": \"sw_r\",\n",
        "\n",
        "        \"epochs\": 100,\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "\n",
        "        \"fs\": 100,\n",
        "\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "\n",
        "        \"tau\": 1.0,\n",
        "    }\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    meta_all = load_mmfit_meta(\n",
        "        meta_csv_path=CONFIG[\"mmfit_meta_csv\"],\n",
        "        target_exercises=CONFIG[\"MMFIT_TARGET_EXERCISES\"],\n",
        "        only_reps=CONFIG[\"MMFIT_ONLY_REPS\"],\n",
        "        require_device=CONFIG[\"MMFIT_REQUIRE_DEVICE\"],\n",
        "    )\n",
        "    if len(meta_all) == 0:\n",
        "        print(\"[MM-Fit] meta is empty after filtering. Check meta_csv / filters.\")\n",
        "        return\n",
        "\n",
        "    # ✅ 활동별 단일-activity LOSO 실행 (subject=participant)\n",
        "    results = []\n",
        "    for act in [\"pushups\", \"lunges\", \"dumbbell_rows\"]:\n",
        "        out = run_loso_for_one_activity(meta_all, act, CONFIG, device)\n",
        "        if out is not None:\n",
        "            results.append(out)\n",
        "\n",
        "    if len(results) > 0:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Activity Summary (single-activity LOSO, subject=participant)\")\n",
        "        print(\"=\"*80)\n",
        "        for r in results:\n",
        "            print(\n",
        "                f\"- {r['activity']}: meanMAE={r['mean_mae']:.3f}, std={r['std_mae']:.3f}, \"\n",
        "                f\"folds={r['n_folds']}, skipped={r['total_skipped']}\"\n",
        "            )\n",
        "        print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo3xwk9Yz5Xy",
        "outputId": "f0720147-880d-4e52-ef15-9525beb68897"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Starting LOSO (count-only, K-auto) + WINDOWING\n",
            "--------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject0 | MAE: 1.38 | [Pred(win): 7.2 / GT: 10][Pred(win): 10.0 / GT: 10][Pred(win): 9.9 / GT: 10][Pred(win): 9.6 / GT: 10][Pred(win): 8.6 / GT: 10][Pred(win): 7.6 / GT: 10][Pred(win): 9.8 / GT: 10][Pred(win): 11.9 / GT: 10][Pred(win): 10.8 / GT: 10][Pred(win): 7.5 / GT: 10][Pred(win): 8.1 / GT: 10][Pred(win): 7.8 / GT: 10][Pred(win): 11.4 / GT: 10][Pred(win): 9.2 / GT: 10][Pred(win): 8.9 / GT: 10][Pred(win): 9.0 / GT: 10][Pred(win): 7.6 / GT: 10][Pred(win): 8.4 / GT: 10]\n",
            "[Fold TEST Summary] subject0 | GT=10.00±0.00 | Pred(win)=9.07±1.34 | Diff=-0.93±1.34 | k_hat(full)=1.15±0.07 | phase_entropy(full)=0.197±0.064 | n_trials=18\n",
            "Fold  2 | Test: subject1 | MAE: 1.71 | [Pred(win): 8.5 / GT: 10][Pred(win): 8.7 / GT: 10][Pred(win): 8.8 / GT: 10][Pred(win): 6.8 / GT: 10][Pred(win): 9.5 / GT: 10][Pred(win): 11.3 / GT: 10][Pred(win): 8.9 / GT: 10][Pred(win): 12.2 / GT: 10][Pred(win): 11.8 / GT: 10][Pred(win): 8.2 / GT: 10][Pred(win): 9.3 / GT: 10][Pred(win): 13.9 / GT: 10][Pred(win): 9.7 / GT: 10][Pred(win): 8.9 / GT: 10][Pred(win): 13.2 / GT: 10][Pred(win): 5.4 / GT: 10][Pred(win): 10.2 / GT: 10][Pred(win): 11.1 / GT: 10]\n",
            "[Fold TEST Summary] subject1 | GT=10.00±0.00 | Pred(win)=9.81±2.08 | Diff=-0.19±2.08 | k_hat(full)=1.13±0.05 | phase_entropy(full)=0.186±0.060 | n_trials=18\n",
            "Fold  3 | Test: subject2 | MAE: 2.17 | [Pred(win): 8.4 / GT: 10][Pred(win): 7.8 / GT: 10][Pred(win): 7.7 / GT: 10][Pred(win): 9.3 / GT: 10][Pred(win): 5.9 / GT: 10]\n",
            "[Fold TEST Summary] subject2 | GT=10.00±0.00 | Pred(win)=7.83±1.12 | Diff=-2.17±1.12 | k_hat(full)=1.06±0.03 | phase_entropy(full)=0.104±0.044 | n_trials=5\n",
            "Fold  4 | Test: subject3 | MAE: 2.40 | [Pred(win): 6.7 / GT: 10][Pred(win): 7.3 / GT: 10][Pred(win): 8.8 / GT: 10]\n",
            "[Fold TEST Summary] subject3 | GT=10.00±0.00 | Pred(win)=7.60±0.88 | Diff=-2.40±0.88 | k_hat(full)=1.04±0.01 | phase_entropy(full)=0.076±0.033 | n_trials=3\n",
            "Fold  5 | Test: subject4 | MAE: 2.99 | [Pred(win): 8.1 / GT: 10][Pred(win): 7.2 / GT: 10][Pred(win): 5.8 / GT: 10]\n",
            "[Fold TEST Summary] subject4 | GT=10.00±0.00 | Pred(win)=7.01±0.94 | Diff=-2.99±0.94 | k_hat(full)=1.06±0.01 | phase_entropy(full)=0.109±0.018 | n_trials=3\n",
            "Fold  6 | Test: subject5 | MAE: 2.42 | [Pred(win): 9.2 / GT: 10][Pred(win): 14.8 / GT: 10][Pred(win): 13.1 / GT: 10][Pred(win): 11.0 / GT: 10]\n",
            "[Fold TEST Summary] subject5 | GT=10.00±0.00 | Pred(win)=12.03±2.12 | Diff=+2.03±2.12 | k_hat(full)=1.05±0.01 | phase_entropy(full)=0.084±0.009 | n_trials=4\n",
            "Fold  7 | Test: subject6 | MAE: 2.52 | [Pred(win): 7.9 / GT: 10][Pred(win): 7.0 / GT: 10][Pred(win): 7.0 / GT: 9][Pred(win): 9.1 / GT: 12]\n",
            "[Fold TEST Summary] subject6 | GT=10.25±1.09 | Pred(win)=7.73±0.85 | Diff=-2.52±0.47 | k_hat(full)=1.14±0.10 | phase_entropy(full)=0.244±0.127 | n_trials=4\n",
            "Fold  8 | Test: subject7 | MAE: 1.68 | [Pred(win): 9.1 / GT: 10][Pred(win): 6.0 / GT: 10][Pred(win): 9.8 / GT: 10]\n",
            "[Fold TEST Summary] subject7 | GT=10.00±0.00 | Pred(win)=8.32±1.65 | Diff=-1.68±1.65 | k_hat(full)=1.11±0.10 | phase_entropy(full)=0.201±0.183 | n_trials=3\n",
            "Fold  9 | Test: subject8 | MAE: 7.18 | [Pred(win): 14.0 / GT: 10][Pred(win): 18.3 / GT: 10][Pred(win): 16.2 / GT: 7]\n",
            "[Fold TEST Summary] subject8 | GT=9.00±1.41 | Pred(win)=16.18±1.76 | Diff=+7.18±2.28 | k_hat(full)=1.04±0.02 | phase_entropy(full)=0.089±0.036 | n_trials=3\n",
            "Fold 10 | Test: subject9 | MAE: 2.79 | [Pred(win): 9.9 / GT: 10][Pred(win): 13.0 / GT: 10][Pred(win): 15.3 / GT: 10]\n",
            "[Fold TEST Summary] subject9 | GT=10.00±0.00 | Pred(win)=12.76±2.19 | Diff=+2.76±2.19 | k_hat(full)=1.07±0.03 | phase_entropy(full)=0.132±0.061 | n_trials=3\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Final LOSO Result (Average MAE): 2.725\n",
            " >>> Standard Deviation: 1.562\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Starting LOSO (count-only, K-auto) + WINDOWING\n",
            "--------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject0 | MAE: 0.68 | [Pred(win): 10.2 / GT: 10][Pred(win): 9.1 / GT: 10][Pred(win): 10.8 / GT: 10][Pred(win): 9.5 / GT: 10][Pred(win): 9.3 / GT: 10][Pred(win): 9.1 / GT: 10][Pred(win): 10.4 / GT: 10][Pred(win): 9.4 / GT: 10][Pred(win): 10.0 / GT: 10][Pred(win): 11.0 / GT: 10][Pred(win): 10.6 / GT: 10][Pred(win): 9.7 / GT: 10][Pred(win): 11.2 / GT: 10][Pred(win): 11.6 / GT: 10][Pred(win): 11.0 / GT: 10][Pred(win): 10.1 / GT: 10][Pred(win): 9.4 / GT: 10][Pred(win): 9.1 / GT: 10]\n",
            "[Fold TEST Summary] subject0 | GT=10.00±0.00 | Pred(win)=10.08±0.78 | Diff=+0.08±0.78 | k_hat(full)=1.01±0.02 | phase_entropy(full)=0.033±0.043 | n_trials=18\n",
            "Fold  2 | Test: subject1 | MAE: 0.54 | [Pred(win): 9.2 / GT: 10][Pred(win): 10.5 / GT: 10][Pred(win): 9.4 / GT: 10][Pred(win): 11.0 / GT: 10][Pred(win): 10.7 / GT: 10][Pred(win): 10.1 / GT: 10][Pred(win): 10.0 / GT: 10][Pred(win): 10.0 / GT: 10][Pred(win): 10.5 / GT: 10][Pred(win): 9.7 / GT: 10][Pred(win): 10.4 / GT: 10][Pred(win): 11.7 / GT: 10][Pred(win): 9.8 / GT: 10][Pred(win): 10.2 / GT: 10][Pred(win): 9.2 / GT: 10][Pred(win): 9.0 / GT: 10][Pred(win): 9.7 / GT: 10]\n",
            "[Fold TEST Summary] subject1 | GT=10.00±0.00 | Pred(win)=10.08±0.69 | Diff=+0.08±0.69 | k_hat(full)=1.01±0.01 | phase_entropy(full)=0.023±0.018 | n_trials=17\n",
            "Fold  3 | Test: subject2 | MAE: 0.12 | [Pred(win): 9.9 / GT: 10][Pred(win): 10.1 / GT: 10][Pred(win): 10.5 / GT: 10][Pred(win): 10.0 / GT: 10][Pred(win): 9.9 / GT: 10][Pred(win): 11.0 / GT: 11]\n",
            "[Fold TEST Summary] subject2 | GT=10.17±0.37 | Pred(win)=10.24±0.39 | Diff=+0.07±0.20 | k_hat(full)=1.00±0.00 | phase_entropy(full)=0.012±0.007 | n_trials=6\n",
            "Fold  4 | Test: subject3 | MAE: 2.17 | [Pred(win): 8.1 / GT: 10][Pred(win): 7.5 / GT: 10][Pred(win): 7.9 / GT: 10]\n",
            "[Fold TEST Summary] subject3 | GT=10.00±0.00 | Pred(win)=7.83±0.27 | Diff=-2.17±0.27 | k_hat(full)=1.00±0.00 | phase_entropy(full)=0.012±0.000 | n_trials=3\n",
            "Fold  5 | Test: subject4 | MAE: 1.25 | [Pred(win): 8.9 / GT: 10][Pred(win): 9.2 / GT: 10][Pred(win): 8.2 / GT: 10]\n",
            "[Fold TEST Summary] subject4 | GT=10.00±0.00 | Pred(win)=8.75±0.38 | Diff=-1.25±0.38 | k_hat(full)=1.00±0.00 | phase_entropy(full)=0.006±0.003 | n_trials=3\n",
            "Fold  6 | Test: subject5 | MAE: 0.70 | [Pred(win): 11.0 / GT: 10][Pred(win): 9.9 / GT: 10][Pred(win): 10.9 / GT: 10]\n",
            "[Fold TEST Summary] subject5 | GT=10.00±0.00 | Pred(win)=10.62±0.52 | Diff=+0.62±0.52 | k_hat(full)=1.01±0.01 | phase_entropy(full)=0.020±0.017 | n_trials=3\n",
            "Fold  7 | Test: subject6 | MAE: 1.39 | [Pred(win): 9.2 / GT: 10][Pred(win): 8.3 / GT: 10][Pred(win): 12.3 / GT: 14]\n",
            "[Fold TEST Summary] subject6 | GT=11.33±1.89 | Pred(win)=9.95±1.71 | Diff=-1.39±0.44 | k_hat(full)=1.02±0.02 | phase_entropy(full)=0.057±0.047 | n_trials=3\n",
            "Fold  8 | Test: subject7 | MAE: 0.32 | [Pred(win): 10.1 / GT: 10][Pred(win): 9.4 / GT: 10][Pred(win): 9.7 / GT: 10]\n",
            "[Fold TEST Summary] subject7 | GT=10.00±0.00 | Pred(win)=9.73±0.28 | Diff=-0.27±0.28 | k_hat(full)=1.01±0.01 | phase_entropy(full)=0.037±0.030 | n_trials=3\n",
            "Fold  9 | Test: subject8 | MAE: 1.21 | [Pred(win): 12.5 / GT: 10][Pred(win): 9.7 / GT: 10][Pred(win): 9.1 / GT: 10]\n",
            "[Fold TEST Summary] subject8 | GT=10.00±0.00 | Pred(win)=10.43±1.46 | Diff=+0.43±1.46 | k_hat(full)=1.01±0.01 | phase_entropy(full)=0.042±0.022 | n_trials=3\n",
            "Fold 10 | Test: subject9 | MAE: 1.77 | [Pred(win): 12.1 / GT: 10][Pred(win): 10.8 / GT: 9][Pred(win): 11.4 / GT: 10]\n",
            "[Fold TEST Summary] subject9 | GT=9.67±0.47 | Pred(win)=11.44±0.53 | Diff=+1.77±0.30 | k_hat(full)=1.00±0.00 | phase_entropy(full)=0.015±0.012 | n_trials=3\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Final LOSO Result (Average MAE): 1.016\n",
            " >>> Standard Deviation: 0.620\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Starting LOSO (count-only, K-auto) + WINDOWING\n",
            "--------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject0 | MAE: 2.80 | [Pred(win): 13.7 / GT: 10][Pred(win): 14.3 / GT: 10][Pred(win): 13.4 / GT: 10][Pred(win): 14.3 / GT: 10][Pred(win): 12.1 / GT: 10][Pred(win): 8.6 / GT: 10][Pred(win): 13.5 / GT: 10][Pred(win): 14.3 / GT: 10][Pred(win): 11.1 / GT: 10][Pred(win): 11.9 / GT: 10][Pred(win): 12.8 / GT: 10][Pred(win): 9.9 / GT: 10][Pred(win): 15.4 / GT: 10][Pred(win): 15.4 / GT: 10][Pred(win): 11.9 / GT: 10][Pred(win): 11.5 / GT: 10][Pred(win): 10.5 / GT: 10][Pred(win): 10.5 / GT: 10][Pred(win): 14.8 / GT: 10]\n",
            "[Fold TEST Summary] subject0 | GT=10.00±0.00 | Pred(win)=12.64±1.91 | Diff=+2.64±1.91 | k_hat(full)=1.48±0.13 | phase_entropy(full)=0.264±0.086 | n_trials=19\n",
            "Fold  2 | Test: subject1 | MAE: 1.82 | [Pred(win): 12.1 / GT: 10][Pred(win): 10.1 / GT: 10][Pred(win): 6.4 / GT: 10][Pred(win): 11.6 / GT: 10][Pred(win): 11.7 / GT: 10][Pred(win): 10.2 / GT: 10][Pred(win): 11.0 / GT: 10][Pred(win): 8.4 / GT: 10][Pred(win): 9.0 / GT: 10][Pred(win): 8.9 / GT: 10][Pred(win): 9.1 / GT: 10][Pred(win): 3.7 / GT: 10][Pred(win): 11.6 / GT: 10][Pred(win): 7.5 / GT: 10][Pred(win): 11.9 / GT: 10][Pred(win): 10.8 / GT: 10][Pred(win): 7.1 / GT: 10]\n",
            "[Fold TEST Summary] subject1 | GT=10.00±0.00 | Pred(win)=9.49±2.25 | Diff=-0.51±2.25 | k_hat(full)=1.47±0.18 | phase_entropy(full)=0.411±0.142 | n_trials=17\n",
            "Fold  3 | Test: subject2 | MAE: 1.41 | [Pred(win): 9.8 / GT: 11][Pred(win): 9.1 / GT: 10][Pred(win): 8.7 / GT: 11][Pred(win): 9.5 / GT: 10][Pred(win): 8.0 / GT: 10][Pred(win): 8.4 / GT: 10]\n",
            "[Fold TEST Summary] subject2 | GT=10.33±0.47 | Pred(win)=8.92±0.61 | Diff=-1.41±0.62 | k_hat(full)=1.06±0.04 | phase_entropy(full)=0.109±0.057 | n_trials=6\n",
            "Fold  4 | Test: subject3 | MAE: 3.14 | [Pred(win): 6.6 / GT: 10][Pred(win): 7.5 / GT: 10][Pred(win): 6.4 / GT: 10]\n",
            "[Fold TEST Summary] subject3 | GT=10.00±0.00 | Pred(win)=6.86±0.47 | Diff=-3.14±0.47 | k_hat(full)=1.06±0.03 | phase_entropy(full)=0.124±0.059 | n_trials=3\n",
            "Fold  5 | Test: subject4 | MAE: 3.45 | [Pred(win): 7.4 / GT: 10][Pred(win): 5.8 / GT: 10][Pred(win): 6.5 / GT: 10]\n",
            "[Fold TEST Summary] subject4 | GT=10.00±0.00 | Pred(win)=6.55±0.66 | Diff=-3.45±0.66 | k_hat(full)=1.07±0.03 | phase_entropy(full)=0.135±0.041 | n_trials=3\n",
            "Fold  6 | Test: subject5 | MAE: 0.79 | [Pred(win): 10.4 / GT: 12][Pred(win): 9.7 / GT: 10][Pred(win): 10.5 / GT: 10]\n",
            "[Fold TEST Summary] subject5 | GT=10.67±0.94 | Pred(win)=10.22±0.35 | Diff=-0.44±0.86 | k_hat(full)=1.13±0.06 | phase_entropy(full)=0.211±0.095 | n_trials=3\n",
            "Fold  7 | Test: subject6 | MAE: 2.81 | [Pred(win): 8.4 / GT: 10][Pred(win): 6.3 / GT: 10][Pred(win): 6.8 / GT: 10]\n",
            "[Fold TEST Summary] subject6 | GT=10.00±0.00 | Pred(win)=7.19±0.89 | Diff=-2.81±0.89 | k_hat(full)=1.04±0.01 | phase_entropy(full)=0.072±0.017 | n_trials=3\n",
            "Fold  8 | Test: subject7 | MAE: 0.66 | [Pred(win): 10.0 / GT: 10][Pred(win): 9.8 / GT: 10][Pred(win): 11.7 / GT: 10]\n",
            "[Fold TEST Summary] subject7 | GT=10.00±0.00 | Pred(win)=10.49±0.87 | Diff=+0.49±0.87 | k_hat(full)=1.03±0.01 | phase_entropy(full)=0.058±0.018 | n_trials=3\n",
            "Fold  9 | Test: subject8 | MAE: 1.12 | [Pred(win): 8.9 / GT: 10][Pred(win): 10.4 / GT: 10][Pred(win): 8.2 / GT: 10]\n",
            "[Fold TEST Summary] subject8 | GT=10.00±0.00 | Pred(win)=9.17±0.95 | Diff=-0.83±0.95 | k_hat(full)=1.04±0.01 | phase_entropy(full)=0.081±0.029 | n_trials=3\n",
            "Fold 10 | Test: subject9 | MAE: 2.12 | [Pred(win): 13.1 / GT: 10][Pred(win): 12.6 / GT: 10][Pred(win): 9.4 / GT: 10]\n",
            "[Fold TEST Summary] subject9 | GT=10.00±0.00 | Pred(win)=11.72±1.65 | Diff=+1.72±1.65 | k_hat(full)=1.06±0.02 | phase_entropy(full)=0.125±0.058 | n_trials=3\n",
            "--------------------------------------------------------------------------------\n",
            " >>> Final LOSO Result (Average MAE): 2.010\n",
            " >>> Standard Deviation: 0.955\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Activity Summary (single-activity LOSO, subject=participant)\n",
            "================================================================================\n",
            "- pushups: meanMAE=2.725, std=1.562, folds=10, skipped=0\n",
            "- lunges: meanMAE=1.016, std=0.620, folds=10, skipped=0\n",
            "- dumbbell_rows: meanMAE=2.010, std=0.955, folds=10, skipped=0\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}