{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Full sweep code (LOSO per-activity) for count-only K-auto + Windowing\n",
        "#\n",
        "# What it does:\n",
        "# 1) Load mHealth once\n",
        "# 2) Prebuild normalized trial cache for 6 activities x 10 subjects\n",
        "# 3) Run 4 independent 1D sweeps in order:\n",
        "#    lambda_smooth -> lambda_phase_ent -> lambda_recon -> lambda_effk\n",
        "#    (each sweep includes 0, other lambdas fixed at base best)\n",
        "# 4) For each (sweep_name, value):\n",
        "#    - For each activity: run LOSO (10 folds)\n",
        "#    - Report per-activity mean MAE/MSE/RMSE and overall macro average\n",
        "#\n",
        "# Notes:\n",
        "# - Logging is minimal (per-activity + overall only).\n",
        "# - This will be slow: (#sweep_values total) * (6 activities) * (10 folds) trainings.\n",
        "#   Adjust CONFIG[\"epochs\"] / sweep grids if needed.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      full_dataset[subj_key][activity_name] = DataFrame(features + maybe others)\n",
        "    \"\"\"\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Loading {len(file_list)} subjects from {data_dir}...\")\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.5) Windowing (TRAIN only)\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True):\n",
        "    \"\"\"\n",
        "    TRAIN: trial -> sliding windows\n",
        "    window label: trial-average rate * window duration\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C)\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        if T < win_len:\n",
        "            win_dur = T / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x,\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[0:{T}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": 0,\n",
        "                \"win_end\": T,\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        last_start = T - win_len\n",
        "        starts = list(range(0, last_start + 1, stride))\n",
        "\n",
        "        for st in starts:\n",
        "            ed = st + win_len\n",
        "            win_dur = win_len / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": st,\n",
        "                \"win_end\": ed,\n",
        "            })\n",
        "\n",
        "        if not drop_last:\n",
        "            last_st = starts[-1] + stride\n",
        "            if last_st < T:\n",
        "                ed = T\n",
        "                win_dur = (ed - last_st) / float(fs)\n",
        "                windows.append({\n",
        "                    \"data\": x[last_st:ed],\n",
        "                    \"count\": rate_trial * win_dur,\n",
        "                    \"meta\": f\"{meta}__win[{last_st}:{ed}]\",\n",
        "                    \"parent_meta\": meta,\n",
        "                    \"parent_T\": T,\n",
        "                    \"win_start\": last_st,\n",
        "                    \"win_end\": ed,\n",
        "                })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.6) Windowing inference (TEST)\n",
        "# ---------------------------------------------------------------------\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    \"\"\"\n",
        "    TEST: trial -> sliding windows inference -> window rate mean -> total count\n",
        "    x_np: (T,C) already normalized\n",
        "    return: pred_count(float)\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    # short trial -> single forward\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)  # (1,C,T)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        return float(rate_hat.item() * total_dur)\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N, win_len, C)\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N, C, win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)  # (B,)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)  # (N,)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.8) Dataset / Collate\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item['data'], dtype=torch.float32).transpose(0, 1)  # (C, T)\n",
        "        count = torch.tensor(item['count'], dtype=torch.float32)\n",
        "        return data, count, item['meta']\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, metas, lengths = [], [], [], [], []\n",
        "    for data, count, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),              # (B, C, T_max)\n",
        "        \"mask\": torch.stack(masks),                    # (B, T_max)\n",
        "        \"count\": torch.stack(counts),                  # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Model\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)            # (B, D, T)\n",
        "        z = z.transpose(1, 2)      # (B, T, D)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)     # (B, D, T)\n",
        "        x_hat = self.net(zt)       # (B, C, T)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)  # [amp_logit | phase_logits...]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)                             # (B,T,1+K)\n",
        "        amp = F.softplus(out[..., 0])                 # (B,T) >=0\n",
        "        phase_logits = out[..., 1:]                   # (B,T,K)\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1) # (B,T,K)\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)              # (B,T,D)\n",
        "        x_hat = self.decoder(z)          # (B,C,T)\n",
        "\n",
        "        amp_t, phase_p, phase_logits = self.rate_head(z, tau=tau)  # (B,T), (B,T,K)\n",
        "        micro_rate_t = amp_t                                  # (B,T)\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)          # (B,K)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)         # (B,)\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6) # (B,T)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"phase_p\": phase_p,\n",
        "            \"rep_rate_t\": rep_rate_t,\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Loss utils\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)              # (B,1,T)\n",
        "    se = (x_hat - x) ** 2                    # (B,C,T)\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps  # valid(B*T)*C\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])  # (B,T-1)\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)  # (B,T)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)  # (B,K)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)  # (B,T,1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Train\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.0075)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)         # (B,C,T)\n",
        "        mask = batch[\"mask\"].to(device)      # (B,T)\n",
        "        y_count = batch[\"count\"].to(device)  # (B,)\n",
        "        length = batch[\"length\"].to(device)  # (B,)\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)  # sec\n",
        "        y_rate = y_count / duration                    # reps/s\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rate_hat, z, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = F.mse_loss(rate_hat, y_rate)\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Trial cache builder (precompute normalized trials once)\n",
        "# ---------------------------------------------------------------------\n",
        "def build_trial_cache(full_data, target_map, feature_map, count_table):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      trials_cache[act_id][subj] = {\n",
        "        'data': (T,C) normalized,\n",
        "        'count': float,\n",
        "        'meta': str\n",
        "      }\n",
        "    \"\"\"\n",
        "    trials_cache = {}\n",
        "    for act_id, act_name in target_map.items():\n",
        "        trials_cache[act_id] = {}\n",
        "        feats = feature_map[act_id]\n",
        "\n",
        "        if act_id not in count_table:\n",
        "            raise ValueError(f\"Missing COUNT_TABLE entry for act_id={act_id}\")\n",
        "\n",
        "        for subj, gt_count in count_table[act_id].items():\n",
        "            if subj not in full_data or act_name not in full_data[subj]:\n",
        "                print(f\"[Skip-cache] Missing data for {subj} - {act_name}\")\n",
        "                continue\n",
        "\n",
        "            raw_df = full_data[subj][act_name][feats]\n",
        "            raw_np = raw_df.values.astype(np.float32)\n",
        "\n",
        "            mean = raw_np.mean(axis=0)\n",
        "            std = raw_np.std(axis=0) + 1e-6\n",
        "            norm_np = (raw_np - mean) / std\n",
        "\n",
        "            trials_cache[act_id][subj] = {\n",
        "                \"data\": norm_np,                 # (T,C)\n",
        "                \"count\": float(gt_count),         # trial total count\n",
        "                \"meta\": f\"{subj}_{act_name}\"\n",
        "            }\n",
        "\n",
        "    return trials_cache\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7) LOSO runner (single activity)\n",
        "# ---------------------------------------------------------------------\n",
        "def eval_single_activity_loso(trials_cache_act, config, device):\n",
        "    \"\"\"\n",
        "    trials_cache_act: dict subj -> trial_item (data/count/meta)\n",
        "    Returns: (mae, mse, rmse) averaged over folds (subjects)\n",
        "    \"\"\"\n",
        "    subjects = sorted(list(trials_cache_act.keys()))\n",
        "    if len(subjects) == 0:\n",
        "        return None\n",
        "\n",
        "    fs = config[\"fs\"]\n",
        "    win_sec = config[\"win_sec\"]\n",
        "    stride_sec = config[\"stride_sec\"]\n",
        "    drop_last = config[\"drop_last\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "\n",
        "    epochs = config[\"epochs\"]\n",
        "    lr = config[\"lr\"]\n",
        "    batch_size = config[\"batch_size\"]\n",
        "\n",
        "    hidden_dim = config[\"hidden_dim\"]\n",
        "    latent_dim = config[\"latent_dim\"]\n",
        "    K_max = config[\"K_max\"]\n",
        "\n",
        "    fold_abs = []\n",
        "    fold_sq = []\n",
        "\n",
        "    for test_subj in subjects:\n",
        "        set_strict_seed(config[\"seed\"])\n",
        "\n",
        "        # build train/test trial lists\n",
        "        train_trials = [trials_cache_act[s] for s in subjects if s != test_subj]\n",
        "        test_trials = [trials_cache_act[test_subj]]\n",
        "\n",
        "        # TRAIN: windowing\n",
        "        train_windows = trial_list_to_windows(\n",
        "            train_trials,\n",
        "            fs=fs, win_sec=win_sec, stride_sec=stride_sec, drop_last=drop_last\n",
        "        )\n",
        "\n",
        "        # DataLoader\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(config[\"seed\"])\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            TrialDataset(train_windows),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            collate_fn=collate_variable_length,\n",
        "            generator=g,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "        input_ch = train_windows[0][\"data\"].shape[1]\n",
        "        model = KAutoCountModel(\n",
        "            input_ch=input_ch,\n",
        "            hidden_dim=hidden_dim,\n",
        "            latent_dim=latent_dim,\n",
        "            K_max=K_max\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "        # train (✅ gradients enabled)\n",
        "        for _ in range(epochs):\n",
        "            train_one_epoch(model, train_loader, optimizer, config, device)\n",
        "            scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # test (trial-level count via windowing inference)  ✅ no_grad only here\n",
        "        item = test_trials[0]\n",
        "        x_np = item[\"data\"]\n",
        "        gt = float(item[\"count\"])\n",
        "        with torch.no_grad():\n",
        "            pred = predict_count_by_windowing(\n",
        "                model, x_np=x_np, fs=fs, win_sec=win_sec, stride_sec=stride_sec,\n",
        "                device=device, tau=tau, batch_size=batch_size\n",
        "            )\n",
        "\n",
        "        err = pred - gt\n",
        "        fold_abs.append(abs(err))\n",
        "        fold_sq.append(err * err)\n",
        "\n",
        "        # free GPU memory fold-by-fold\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    mae = float(np.mean(fold_abs))\n",
        "    mse = float(np.mean(fold_sq))\n",
        "    rmse = float(np.sqrt(mse))\n",
        "    return mae, mse, rmse\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8) Sweep helpers\n",
        "# ---------------------------------------------------------------------\n",
        "def make_sweep_values(base_val, multipliers=(0.25, 0.5, 1.0, 2.0, 4.0)):\n",
        "    \"\"\"\n",
        "    Must include 0.\n",
        "    Creates: [0] + [base_val * m for m in multipliers]\n",
        "    Unique + sorted.\n",
        "    \"\"\"\n",
        "    vals = [0.0]\n",
        "    for m in multipliers:\n",
        "        vals.append(float(base_val) * float(m))\n",
        "    vals = sorted(set([float(v) for v in vals]))\n",
        "    return vals\n",
        "\n",
        "\n",
        "def run_one_setting(full_data_cache, base_config, device, sweep_name, sweep_value):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      metrics_by_act: dict act_id -> (mae,mse,rmse)\n",
        "      overall_macro: (mae,mse,rmse)\n",
        "    \"\"\"\n",
        "    config = copy.deepcopy(base_config)\n",
        "    config[sweep_name] = float(sweep_value)\n",
        "\n",
        "    metrics_by_act = {}\n",
        "    maes, mses, rmses = [], [], []\n",
        "\n",
        "    for act_id in config[\"TARGET_ACTIVITIES_MAP\"].keys():\n",
        "        trials_cache_act = full_data_cache[act_id]\n",
        "        out = eval_single_activity_loso(trials_cache_act, config, device)\n",
        "        if out is None:\n",
        "            continue\n",
        "        mae, mse, rmse = out\n",
        "        metrics_by_act[act_id] = (mae, mse, rmse)\n",
        "        maes.append(mae)\n",
        "        mses.append(mse)\n",
        "        rmses.append(rmse)\n",
        "\n",
        "    overall = (float(np.mean(maes)), float(np.mean(mses)), float(np.mean(rmses)))\n",
        "    return config, metrics_by_act, overall\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 9) Main\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "        # TODO: adjust to your path\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "\n",
        "        # 6 activities\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            6:  'Waist bends forward',\n",
        "            7:  'Frontal elevation of arms',\n",
        "            8:  'Knees bending',\n",
        "            10: 'Jogging',\n",
        "            11: 'Running',\n",
        "            12: 'Jump front & back'\n",
        "        },\n",
        "\n",
        "        # fixed 15 channels (chest acc3 + ankle acc3 + ankle gyro3 + arm acc3 + arm gyro3)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            6:  ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            7:  ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            8:  ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            10: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            11: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            12: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        # Training Params\n",
        "        \"epochs\": 100, # 30\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "        \"fs\": 50,\n",
        "\n",
        "        # Windowing Params\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        # Model\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        # Base best loss weights\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "\n",
        "        # temperature\n",
        "        \"tau\": 1.0,\n",
        "\n",
        "        # Count-only labels\n",
        "        \"COUNT_TABLE\": {\n",
        "            6: {\n",
        "                \"subject1\": 21, \"subject2\": 19, \"subject3\": 21, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 21, \"subject9\": 21, \"subject10\": 20,\n",
        "            },\n",
        "            7: {\n",
        "                \"subject1\": 20, \"subject2\": 20, \"subject3\": 20, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 19, \"subject9\": 19, \"subject10\": 20,\n",
        "            },\n",
        "            8: {\n",
        "                \"subject1\": 20, \"subject2\": 21, \"subject3\": 21, \"subject4\": 19, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 21, \"subject8\": 21, \"subject9\": 21, \"subject10\": 21,\n",
        "            },\n",
        "            10: {\n",
        "                \"subject1\": 157, \"subject2\": 161, \"subject3\": 154, \"subject4\": 154, \"subject5\": 160,\n",
        "                \"subject6\": 156, \"subject7\": 153, \"subject8\": 160, \"subject9\": 166, \"subject10\": 156,\n",
        "            },\n",
        "            11: {\n",
        "                \"subject1\": 165, \"subject2\": 158, \"subject3\": 174, \"subject4\": 163, \"subject5\": 157,\n",
        "                \"subject6\": 172, \"subject7\": 149, \"subject8\": 166, \"subject9\": 174, \"subject10\": 172,\n",
        "            },\n",
        "            12: {\n",
        "                \"subject1\": 20, \"subject2\": 22, \"subject3\": 21, \"subject4\": 21, \"subject5\": 20,\n",
        "                \"subject6\": 21, \"subject7\": 19, \"subject8\": 20, \"subject9\": 20, \"subject10\": 20,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # 1) load raw data once\n",
        "    full_data = load_mhealth_dataset(CONFIG[\"data_dir\"], CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"COLUMN_NAMES\"])\n",
        "    if not full_data:\n",
        "        print(\"[Error] full_data is empty. Check path / file naming.\")\n",
        "        return\n",
        "\n",
        "    # 2) build normalized trial cache once\n",
        "    trials_cache_all = build_trial_cache(\n",
        "        full_data=full_data,\n",
        "        target_map=CONFIG[\"TARGET_ACTIVITIES_MAP\"],\n",
        "        feature_map=CONFIG[\"ACT_FEATURE_MAP\"],\n",
        "        count_table=CONFIG[\"COUNT_TABLE\"]\n",
        "    )\n",
        "\n",
        "    # 3) sweep plan (order fixed)\n",
        "    sweep_plan = [\n",
        "        (\"lambda_smooth\", CONFIG[\"lambda_smooth\"]),\n",
        "        (\"lambda_phase_ent\", CONFIG[\"lambda_phase_ent\"]),\n",
        "        (\"lambda_recon\", CONFIG[\"lambda_recon\"]),\n",
        "        (\"lambda_effk\", CONFIG[\"lambda_effk\"]),\n",
        "    ]\n",
        "\n",
        "    # ✅ User-specified sweep grids (must include 0)\n",
        "    SWEEP_VALUES = {\n",
        "        \"lambda_recon\":     [0, 0.25, 0.5, 0.75, 1.0, 1.5],\n",
        "        \"lambda_smooth\":    [0, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "        \"lambda_phase_ent\": [0, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "        \"lambda_effk\":      [0, 0.005, 0.0075, 0.01, 0.05, 0.1],\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 92)\n",
        "    print(\"LOSS WEIGHT SENSITIVITY SWEEP (each sweep includes 0; others fixed at base best)\")\n",
        "    print(\"=\" * 92)\n",
        "\n",
        "    act_ids = list(CONFIG[\"TARGET_ACTIVITIES_MAP\"].keys())\n",
        "    act_names = CONFIG[\"TARGET_ACTIVITIES_MAP\"]\n",
        "\n",
        "    for sweep_name, base_val in sweep_plan:\n",
        "        # ✅ use user grid (fallback: original make_sweep_values if missing key)\n",
        "        if sweep_name in SWEEP_VALUES:\n",
        "            sweep_vals = [float(v) for v in SWEEP_VALUES[sweep_name]]\n",
        "        else:\n",
        "            # (should not happen)\n",
        "            sweep_vals = make_sweep_values(base_val, multipliers=(0.25, 0.5, 1.0, 2.0, 4.0))\n",
        "\n",
        "        # keep unique + sorted, preserve 0\n",
        "        sweep_vals = sorted(set(sweep_vals))\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 92)\n",
        "        print(f\"[SWEEP] {sweep_name}  (base={base_val})  values={sweep_vals}\")\n",
        "        print(\"-\" * 92)\n",
        "\n",
        "        for v in sweep_vals:\n",
        "            cfg_used, metrics_by_act, overall = run_one_setting(\n",
        "                full_data_cache=trials_cache_all,\n",
        "                base_config=CONFIG,\n",
        "                device=device,\n",
        "                sweep_name=sweep_name,\n",
        "                sweep_value=v\n",
        "            )\n",
        "\n",
        "            # ---- minimal log (per-activity + overall only) ----\n",
        "            print(f\"\\n{sweep_name} = {v}\")\n",
        "            for act_id in act_ids:\n",
        "                if act_id not in metrics_by_act:\n",
        "                    continue\n",
        "                mae, mse, rmse = metrics_by_act[act_id]\n",
        "                print(f\"  Act {act_id:>2d} ({act_names[act_id]}): \"\n",
        "                      f\"MAE={mae:.4f} | MSE={mse:.4f} | RMSE={rmse:.4f}\")\n",
        "\n",
        "            o_mae, o_mse, o_rmse = overall\n",
        "            print(f\"  OVERALL (macro over 6 acts): MAE={o_mae:.4f} | MSE={o_mse:.4f} | RMSE={o_rmse:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 92)\n",
        "    print(\"DONE.\")\n",
        "    print(\"=\" * 92)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfgogBkSGhmy",
        "outputId": "423285ac-5039-45a1-9ab9-7a4314383023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loading 10 subjects from /content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET...\n",
            "\n",
            "============================================================================================\n",
            "LOSS WEIGHT SENSITIVITY SWEEP (each sweep includes 0; others fixed at base best)\n",
            "============================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[SWEEP] lambda_smooth  (base=0.05)  values=[0.0, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "lambda_smooth = 0.0\n",
            "  Act  6 (Waist bends forward): MAE=5.0936 | MSE=33.3969 | RMSE=5.7790\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.8823 | MSE=11.4221 | RMSE=3.3797\n",
            "  Act  8 (Knees bending): MAE=4.6755 | MSE=39.0947 | RMSE=6.2526\n",
            "  Act 10 (Jogging): MAE=8.4237 | MSE=188.6386 | RMSE=13.7346\n",
            "  Act 11 (Running): MAE=13.9437 | MSE=258.0601 | RMSE=16.0642\n",
            "  Act 12 (Jump front & back): MAE=1.4359 | MSE=3.0381 | RMSE=1.7430\n",
            "  OVERALL (macro over 6 acts): MAE=6.0758 | MSE=88.9417 | RMSE=7.8255\n",
            "\n",
            "lambda_smooth = 0.01\n",
            "  Act  6 (Waist bends forward): MAE=4.9525 | MSE=31.3524 | RMSE=5.5993\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.7865 | MSE=10.9748 | RMSE=3.3128\n",
            "  Act  8 (Knees bending): MAE=4.6192 | MSE=37.4753 | RMSE=6.1217\n",
            "  Act 10 (Jogging): MAE=8.4356 | MSE=187.4291 | RMSE=13.6905\n",
            "  Act 11 (Running): MAE=14.0352 | MSE=261.3684 | RMSE=16.1669\n",
            "  Act 12 (Jump front & back): MAE=1.4255 | MSE=2.9998 | RMSE=1.7320\n",
            "  OVERALL (macro over 6 acts): MAE=6.0424 | MSE=88.5999 | RMSE=7.7705\n",
            "\n",
            "lambda_smooth = 0.05\n",
            "  Act  6 (Waist bends forward): MAE=4.3955 | MSE=24.4395 | RMSE=4.9436\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4466 | MSE=9.7797 | RMSE=3.1273\n",
            "  Act  8 (Knees bending): MAE=4.3990 | MSE=32.2751 | RMSE=5.6811\n",
            "  Act 10 (Jogging): MAE=8.5011 | MSE=179.5581 | RMSE=13.3999\n",
            "  Act 11 (Running): MAE=14.4115 | MSE=275.4088 | RMSE=16.5954\n",
            "  Act 12 (Jump front & back): MAE=1.4238 | MSE=2.8535 | RMSE=1.6892\n",
            "  OVERALL (macro over 6 acts): MAE=5.9296 | MSE=87.3858 | RMSE=7.5728\n",
            "\n",
            "lambda_smooth = 0.1\n",
            "  Act  6 (Waist bends forward): MAE=3.9373 | MSE=18.5592 | RMSE=4.3080\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.2693 | MSE=9.2303 | RMSE=3.0381\n",
            "  Act  8 (Knees bending): MAE=4.2005 | MSE=27.2702 | RMSE=5.2221\n",
            "  Act 10 (Jogging): MAE=8.4561 | MSE=168.5367 | RMSE=12.9822\n",
            "  Act 11 (Running): MAE=14.7617 | MSE=290.0699 | RMSE=17.0314\n",
            "  Act 12 (Jump front & back): MAE=1.4238 | MSE=2.5874 | RMSE=1.6085\n",
            "  OVERALL (macro over 6 acts): MAE=5.8414 | MSE=86.0423 | RMSE=7.3651\n",
            "\n",
            "lambda_smooth = 0.5\n",
            "  Act  6 (Waist bends forward): MAE=3.6658 | MSE=19.0660 | RMSE=4.3665\n",
            "  Act  7 (Frontal elevation of arms): MAE=3.1174 | MSE=17.3042 | RMSE=4.1598\n",
            "  Act  8 (Knees bending): MAE=3.4292 | MSE=12.9388 | RMSE=3.5971\n",
            "  Act 10 (Jogging): MAE=6.5147 | MSE=73.3502 | RMSE=8.5645\n",
            "  Act 11 (Running): MAE=15.7160 | MSE=299.4900 | RMSE=17.3058\n",
            "  Act 12 (Jump front & back): MAE=0.8284 | MSE=1.5897 | RMSE=1.2608\n",
            "  OVERALL (macro over 6 acts): MAE=5.5453 | MSE=70.6232 | RMSE=6.5424\n",
            "\n",
            "lambda_smooth = 1.0\n",
            "  Act  6 (Waist bends forward): MAE=4.1710 | MSE=27.0145 | RMSE=5.1975\n",
            "  Act  7 (Frontal elevation of arms): MAE=5.5265 | MSE=40.8896 | RMSE=6.3945\n",
            "  Act  8 (Knees bending): MAE=4.4034 | MSE=22.0682 | RMSE=4.6977\n",
            "  Act 10 (Jogging): MAE=4.9284 | MSE=35.8287 | RMSE=5.9857\n",
            "  Act 11 (Running): MAE=14.3043 | MSE=276.5697 | RMSE=16.6304\n",
            "  Act 12 (Jump front & back): MAE=1.1664 | MSE=1.9582 | RMSE=1.3994\n",
            "  OVERALL (macro over 6 acts): MAE=5.7500 | MSE=67.3881 | RMSE=6.7175\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[SWEEP] lambda_phase_ent  (base=0.01)  values=[0.0, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "lambda_phase_ent = 0.0\n",
            "  Act  6 (Waist bends forward): MAE=4.1049 | MSE=21.5754 | RMSE=4.6449\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.2879 | MSE=9.2160 | RMSE=3.0358\n",
            "  Act  8 (Knees bending): MAE=4.4262 | MSE=30.7864 | RMSE=5.5485\n",
            "  Act 10 (Jogging): MAE=8.3606 | MSE=163.2376 | RMSE=12.7764\n",
            "  Act 11 (Running): MAE=14.5517 | MSE=280.0547 | RMSE=16.7348\n",
            "  Act 12 (Jump front & back): MAE=1.4263 | MSE=2.6780 | RMSE=1.6365\n",
            "  OVERALL (macro over 6 acts): MAE=5.8596 | MSE=84.5914 | RMSE=7.3962\n",
            "\n",
            "lambda_phase_ent = 0.01\n",
            "  Act  6 (Waist bends forward): MAE=4.3955 | MSE=24.4395 | RMSE=4.9436\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4466 | MSE=9.7797 | RMSE=3.1273\n",
            "  Act  8 (Knees bending): MAE=4.3990 | MSE=32.2751 | RMSE=5.6811\n",
            "  Act 10 (Jogging): MAE=8.5011 | MSE=179.5581 | RMSE=13.3999\n",
            "  Act 11 (Running): MAE=14.4115 | MSE=275.4088 | RMSE=16.5954\n",
            "  Act 12 (Jump front & back): MAE=1.4238 | MSE=2.8535 | RMSE=1.6892\n",
            "  OVERALL (macro over 6 acts): MAE=5.9296 | MSE=87.3858 | RMSE=7.5728\n",
            "\n",
            "lambda_phase_ent = 0.05\n",
            "  Act  6 (Waist bends forward): MAE=5.2958 | MSE=33.2825 | RMSE=5.7691\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.8423 | MSE=11.1909 | RMSE=3.3453\n",
            "  Act  8 (Knees bending): MAE=4.0880 | MSE=28.1530 | RMSE=5.3059\n",
            "  Act 10 (Jogging): MAE=8.4031 | MSE=234.0876 | RMSE=15.2999\n",
            "  Act 11 (Running): MAE=13.4017 | MSE=250.4495 | RMSE=15.8256\n",
            "  Act 12 (Jump front & back): MAE=1.7163 | MSE=3.9585 | RMSE=1.9896\n",
            "  OVERALL (macro over 6 acts): MAE=5.9579 | MSE=93.5204 | RMSE=7.9226\n",
            "\n",
            "lambda_phase_ent = 0.1\n",
            "  Act  6 (Waist bends forward): MAE=5.2680 | MSE=33.2219 | RMSE=5.7638\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.8876 | MSE=11.7471 | RMSE=3.4274\n",
            "  Act  8 (Knees bending): MAE=4.5825 | MSE=35.8506 | RMSE=5.9875\n",
            "  Act 10 (Jogging): MAE=8.0728 | MSE=216.3774 | RMSE=14.7098\n",
            "  Act 11 (Running): MAE=12.5103 | MSE=216.6094 | RMSE=14.7177\n",
            "  Act 12 (Jump front & back): MAE=2.1605 | MSE=6.0060 | RMSE=2.4507\n",
            "  OVERALL (macro over 6 acts): MAE=5.9136 | MSE=86.6354 | RMSE=7.8428\n",
            "\n",
            "lambda_phase_ent = 0.5\n",
            "  Act  6 (Waist bends forward): MAE=4.4442 | MSE=24.6942 | RMSE=4.9693\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.7940 | MSE=11.5707 | RMSE=3.4016\n",
            "  Act  8 (Knees bending): MAE=3.2103 | MSE=15.7182 | RMSE=3.9646\n",
            "  Act 10 (Jogging): MAE=4.8243 | MSE=74.8029 | RMSE=8.6489\n",
            "  Act 11 (Running): MAE=11.4264 | MSE=180.6990 | RMSE=13.4424\n",
            "  Act 12 (Jump front & back): MAE=1.5249 | MSE=3.9855 | RMSE=1.9964\n",
            "  OVERALL (macro over 6 acts): MAE=4.7040 | MSE=51.9117 | RMSE=6.0705\n",
            "\n",
            "lambda_phase_ent = 1.0\n",
            "  Act  6 (Waist bends forward): MAE=4.0571 | MSE=21.9475 | RMSE=4.6848\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.9226 | MSE=13.3605 | RMSE=3.6552\n",
            "  Act  8 (Knees bending): MAE=2.8271 | MSE=11.4733 | RMSE=3.3872\n",
            "  Act 10 (Jogging): MAE=8.0576 | MSE=276.5512 | RMSE=16.6298\n",
            "  Act 11 (Running): MAE=14.8844 | MSE=284.1356 | RMSE=16.8563\n",
            "  Act 12 (Jump front & back): MAE=1.7350 | MSE=5.2852 | RMSE=2.2989\n",
            "  OVERALL (macro over 6 acts): MAE=5.7473 | MSE=102.1255 | RMSE=7.9187\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[SWEEP] lambda_recon  (base=1.0)  values=[0.0, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "lambda_recon = 0.0\n",
            "  Act  6 (Waist bends forward): MAE=5.2459 | MSE=44.6314 | RMSE=6.6807\n",
            "  Act  7 (Frontal elevation of arms): MAE=3.1246 | MSE=15.8832 | RMSE=3.9854\n",
            "  Act  8 (Knees bending): MAE=1.8128 | MSE=4.3725 | RMSE=2.0911\n",
            "  Act 10 (Jogging): MAE=5.6329 | MSE=65.3763 | RMSE=8.0856\n",
            "  Act 11 (Running): MAE=11.7529 | MSE=179.2672 | RMSE=13.3891\n",
            "  Act 12 (Jump front & back): MAE=2.7353 | MSE=8.8232 | RMSE=2.9704\n",
            "  OVERALL (macro over 6 acts): MAE=5.0507 | MSE=53.0590 | RMSE=6.2004\n",
            "\n",
            "lambda_recon = 0.25\n",
            "  Act  6 (Waist bends forward): MAE=5.0661 | MSE=34.0681 | RMSE=5.8368\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.6709 | MSE=10.1831 | RMSE=3.1911\n",
            "  Act  8 (Knees bending): MAE=3.7108 | MSE=20.4882 | RMSE=4.5264\n",
            "  Act 10 (Jogging): MAE=6.1954 | MSE=68.9441 | RMSE=8.3033\n",
            "  Act 11 (Running): MAE=18.6579 | MSE=427.5493 | RMSE=20.6773\n",
            "  Act 12 (Jump front & back): MAE=2.0919 | MSE=6.3239 | RMSE=2.5147\n",
            "  OVERALL (macro over 6 acts): MAE=6.3988 | MSE=94.5928 | RMSE=7.5083\n",
            "\n",
            "lambda_recon = 0.5\n",
            "  Act  6 (Waist bends forward): MAE=4.9302 | MSE=29.9819 | RMSE=5.4756\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.3922 | MSE=9.5772 | RMSE=3.0947\n",
            "  Act  8 (Knees bending): MAE=5.0438 | MSE=40.3749 | RMSE=6.3541\n",
            "  Act 10 (Jogging): MAE=7.1773 | MSE=118.4482 | RMSE=10.8834\n",
            "  Act 11 (Running): MAE=18.2357 | MSE=426.7788 | RMSE=20.6586\n",
            "  Act 12 (Jump front & back): MAE=2.0104 | MSE=5.8530 | RMSE=2.4193\n",
            "  OVERALL (macro over 6 acts): MAE=6.6316 | MSE=105.1690 | RMSE=8.1476\n",
            "\n",
            "lambda_recon = 0.75\n",
            "  Act  6 (Waist bends forward): MAE=4.6550 | MSE=26.8407 | RMSE=5.1808\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.3643 | MSE=9.7080 | RMSE=3.1158\n",
            "  Act  8 (Knees bending): MAE=4.1492 | MSE=28.6212 | RMSE=5.3499\n",
            "  Act 10 (Jogging): MAE=9.2999 | MSE=190.3404 | RMSE=13.7964\n",
            "  Act 11 (Running): MAE=16.6333 | MSE=371.0212 | RMSE=19.2619\n",
            "  Act 12 (Jump front & back): MAE=1.0922 | MSE=2.6000 | RMSE=1.6124\n",
            "  OVERALL (macro over 6 acts): MAE=6.3656 | MSE=104.8552 | RMSE=8.0529\n",
            "\n",
            "lambda_recon = 1.0\n",
            "  Act  6 (Waist bends forward): MAE=4.3955 | MSE=24.4395 | RMSE=4.9436\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4466 | MSE=9.7797 | RMSE=3.1273\n",
            "  Act  8 (Knees bending): MAE=4.3990 | MSE=32.2751 | RMSE=5.6811\n",
            "  Act 10 (Jogging): MAE=8.5011 | MSE=179.5581 | RMSE=13.3999\n",
            "  Act 11 (Running): MAE=14.4115 | MSE=275.4088 | RMSE=16.5954\n",
            "  Act 12 (Jump front & back): MAE=1.4238 | MSE=2.8535 | RMSE=1.6892\n",
            "  OVERALL (macro over 6 acts): MAE=5.9296 | MSE=87.3858 | RMSE=7.5728\n",
            "\n",
            "lambda_recon = 1.5\n",
            "  Act  6 (Waist bends forward): MAE=4.2797 | MSE=25.3564 | RMSE=5.0355\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4558 | MSE=9.8236 | RMSE=3.1343\n",
            "  Act  8 (Knees bending): MAE=4.6885 | MSE=36.3967 | RMSE=6.0330\n",
            "  Act 10 (Jogging): MAE=7.2841 | MSE=90.9952 | RMSE=9.5391\n",
            "  Act 11 (Running): MAE=13.2900 | MSE=219.4768 | RMSE=14.8147\n",
            "  Act 12 (Jump front & back): MAE=0.8058 | MSE=1.5296 | RMSE=1.2368\n",
            "  OVERALL (macro over 6 acts): MAE=5.4673 | MSE=63.9297 | RMSE=6.6322\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[SWEEP] lambda_effk  (base=0.0075)  values=[0.0, 0.005, 0.0075, 0.01, 0.05, 0.1]\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "lambda_effk = 0.0\n",
            "  Act  6 (Waist bends forward): MAE=3.7442 | MSE=19.5727 | RMSE=4.4241\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4806 | MSE=10.6932 | RMSE=3.2700\n",
            "  Act  8 (Knees bending): MAE=3.8435 | MSE=20.7207 | RMSE=4.5520\n",
            "  Act 10 (Jogging): MAE=8.0737 | MSE=165.4652 | RMSE=12.8633\n",
            "  Act 11 (Running): MAE=14.5145 | MSE=283.9381 | RMSE=16.8505\n",
            "  Act 12 (Jump front & back): MAE=1.3099 | MSE=2.1777 | RMSE=1.4757\n",
            "  OVERALL (macro over 6 acts): MAE=5.6611 | MSE=83.7613 | RMSE=7.2393\n",
            "\n",
            "lambda_effk = 0.005\n",
            "  Act  6 (Waist bends forward): MAE=3.9453 | MSE=22.5035 | RMSE=4.7438\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4284 | MSE=9.2161 | RMSE=3.0358\n",
            "  Act  8 (Knees bending): MAE=4.3586 | MSE=29.6346 | RMSE=5.4438\n",
            "  Act 10 (Jogging): MAE=8.3946 | MSE=175.1480 | RMSE=13.2344\n",
            "  Act 11 (Running): MAE=14.5151 | MSE=279.2590 | RMSE=16.7110\n",
            "  Act 12 (Jump front & back): MAE=1.4852 | MSE=2.7525 | RMSE=1.6591\n",
            "  OVERALL (macro over 6 acts): MAE=5.8545 | MSE=86.4189 | RMSE=7.4713\n",
            "\n",
            "lambda_effk = 0.0075\n",
            "  Act  6 (Waist bends forward): MAE=4.3955 | MSE=24.4395 | RMSE=4.9436\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4466 | MSE=9.7797 | RMSE=3.1273\n",
            "  Act  8 (Knees bending): MAE=4.3990 | MSE=32.2751 | RMSE=5.6811\n",
            "  Act 10 (Jogging): MAE=8.5011 | MSE=179.5581 | RMSE=13.3999\n",
            "  Act 11 (Running): MAE=14.4115 | MSE=275.4088 | RMSE=16.5954\n",
            "  Act 12 (Jump front & back): MAE=1.4238 | MSE=2.8535 | RMSE=1.6892\n",
            "  OVERALL (macro over 6 acts): MAE=5.9296 | MSE=87.3858 | RMSE=7.5728\n",
            "\n",
            "lambda_effk = 0.01\n",
            "  Act  6 (Waist bends forward): MAE=4.6405 | MSE=26.5406 | RMSE=5.1518\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.4336 | MSE=9.8766 | RMSE=3.1427\n",
            "  Act  8 (Knees bending): MAE=4.3837 | MSE=32.7971 | RMSE=5.7269\n",
            "  Act 10 (Jogging): MAE=8.5404 | MSE=184.3602 | RMSE=13.5779\n",
            "  Act 11 (Running): MAE=14.2493 | MSE=270.1680 | RMSE=16.4368\n",
            "  Act 12 (Jump front & back): MAE=1.4169 | MSE=2.9336 | RMSE=1.7128\n",
            "  OVERALL (macro over 6 acts): MAE=5.9441 | MSE=87.7794 | RMSE=7.6248\n",
            "\n",
            "lambda_effk = 0.05\n",
            "  Act  6 (Waist bends forward): MAE=4.8182 | MSE=31.3505 | RMSE=5.5992\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.1268 | MSE=8.9742 | RMSE=2.9957\n",
            "  Act  8 (Knees bending): MAE=4.7652 | MSE=36.9780 | RMSE=6.0810\n",
            "  Act 10 (Jogging): MAE=7.2346 | MSE=168.1919 | RMSE=12.9689\n",
            "  Act 11 (Running): MAE=12.5264 | MSE=234.4415 | RMSE=15.3115\n",
            "  Act 12 (Jump front & back): MAE=1.1711 | MSE=3.1269 | RMSE=1.7683\n",
            "  OVERALL (macro over 6 acts): MAE=5.4404 | MSE=80.5105 | RMSE=7.4541\n",
            "\n",
            "lambda_effk = 0.1\n",
            "  Act  6 (Waist bends forward): MAE=4.5641 | MSE=28.7205 | RMSE=5.3591\n",
            "  Act  7 (Frontal elevation of arms): MAE=2.2634 | MSE=9.8600 | RMSE=3.1401\n",
            "  Act  8 (Knees bending): MAE=3.5703 | MSE=19.6682 | RMSE=4.4349\n",
            "  Act 10 (Jogging): MAE=6.4539 | MSE=113.4524 | RMSE=10.6514\n",
            "  Act 11 (Running): MAE=17.7283 | MSE=425.6774 | RMSE=20.6320\n",
            "  Act 12 (Jump front & back): MAE=2.8604 | MSE=9.2628 | RMSE=3.0435\n",
            "  OVERALL (macro over 6 acts): MAE=6.2401 | MSE=101.1069 | RMSE=7.8768\n",
            "\n",
            "============================================================================================\n",
            "DONE.\n",
            "============================================================================================\n"
          ]
        }
      ]
    }
  ]
}