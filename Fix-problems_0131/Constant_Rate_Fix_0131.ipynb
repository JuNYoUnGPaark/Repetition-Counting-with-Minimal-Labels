{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TrivialWeight (Energy-based) Window Supervision for Count-only K-auto\n",
        "# ✅ Runs ALL activities: {6,7,8,10,12}\n",
        "# - Core model/logic unchanged\n",
        "# - Only change vs Constant-rate baseline:\n",
        "#     TRAIN loss_rate = weighted MSE using per-window energy weight\n",
        "# - TEST stays identical (windowing inference)\n",
        "# - Output: per-activity LOSO MAE mean±std + per-fold logs\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Loading {len(file_list)} subjects from {data_dir}...\")\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "def prepare_trial_list(label_config, full_data, target_map, feature_map):\n",
        "    trial_list = []\n",
        "    for subj, act_id, gt_count in label_config:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if subj in full_data and act_name in full_data[subj]:\n",
        "            raw_df = full_data[subj][act_name][feats]\n",
        "            raw_np = raw_df.values.astype(np.float32)\n",
        "\n",
        "            # per-trial z-score normalization (same as your reference)\n",
        "            mean = raw_np.mean(axis=0)\n",
        "            std = raw_np.std(axis=0) + 1e-6\n",
        "            norm_np = (raw_np - mean) / std\n",
        "\n",
        "            trial_list.append({\n",
        "                \"data\": norm_np,              # (T,C)\n",
        "                \"count\": float(gt_count),     # trial total count\n",
        "                \"meta\": f\"{subj}_{act_name}\"\n",
        "            })\n",
        "        else:\n",
        "            print(f\"[Skip] Missing data for {subj} - {act_name}\")\n",
        "\n",
        "    return trial_list\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Windowing + TrivialWeight\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True,\n",
        "                          energy_clip=(0.0, 1.0), energy_eps=1e-6):\n",
        "    \"\"\"\n",
        "    TRAIN only:\n",
        "      - window label from trial-average rate (constant proxy)\n",
        "      - weight from window energy proxy (trivial weighting)\n",
        "        w_i = clip(E_i / median(E_trial), 0..1)\n",
        "        E_i = mean(x^2) on normalized window signal\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C) normalized\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        # window slices\n",
        "        if T < win_len:\n",
        "            slices = [(0, T)]\n",
        "        else:\n",
        "            last_start = T - win_len\n",
        "            starts = list(range(0, last_start + 1, stride))\n",
        "            slices = [(st, st + win_len) for st in starts]\n",
        "            if not drop_last:\n",
        "                last_st = starts[-1] + stride\n",
        "                if last_st < T:\n",
        "                    slices.append((last_st, T))\n",
        "\n",
        "        # energies per window\n",
        "        energies = []\n",
        "        for (st, ed) in slices:\n",
        "            xw = x[st:ed]\n",
        "            Ew = float(np.mean(xw * xw))\n",
        "            energies.append(Ew)\n",
        "        energies = np.asarray(energies, dtype=np.float32)\n",
        "\n",
        "        med = float(np.median(energies)) if energies.size > 0 else 0.0\n",
        "        denom = max(med, energy_eps)\n",
        "        w = energies / denom\n",
        "        w = np.clip(w, energy_clip[0], energy_clip[1]).astype(np.float32)\n",
        "\n",
        "        # pack\n",
        "        for idx, (st, ed) in enumerate(slices):\n",
        "            win_dur = (ed - st) / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,   # proxy count label (same as constant-rate)\n",
        "                \"weight\": float(w[idx]),         # ✅ trivial weight\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": st,\n",
        "                \"win_end\": ed,\n",
        "            })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    \"\"\"\n",
        "    TEST only: identical to your reference\n",
        "      trial -> windows -> avg rate -> total count\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        pred_count = float(rate_hat.item() * total_dur)\n",
        "        return pred_count, np.array([float(rate_hat.item())], dtype=np.float32)\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N,win_len,C)\n",
        "\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N,C,win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count), rates\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Dataset / Collate\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item[\"data\"], dtype=torch.float32).transpose(0, 1)  # (C,T)\n",
        "        count = torch.tensor(item[\"count\"], dtype=torch.float32)\n",
        "        weight = torch.tensor(item.get(\"weight\", 1.0), dtype=torch.float32)\n",
        "        return data, count, weight, item[\"meta\"]\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, weights, metas, lengths = [], [], [], [], [], []\n",
        "    for data, count, w, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        weights.append(w)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),           # (B,C,Tmax)\n",
        "        \"mask\": torch.stack(masks),                 # (B,Tmax)\n",
        "        \"count\": torch.stack(counts),               # (B,)\n",
        "        \"weight\": torch.stack(weights),             # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Model (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        z = z.transpose(1, 2)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)\n",
        "        x_hat = self.net(zt)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)\n",
        "        amp = F.softplus(out[..., 0])\n",
        "        phase_logits = out[..., 1:]\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1)\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6, k_hidden=64):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "\n",
        "        amp_t, phase_p, phase_logits = self.rate_head(z, tau=tau)\n",
        "        micro_rate_t = amp_t\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"phase_p\": phase_p,\n",
        "            \"phase_logits\": phase_logits,\n",
        "            \"micro_rate_t\": micro_rate_t,\n",
        "            \"rep_rate_t\": rep_rate_t,\n",
        "            \"k_hat\": k_hat,\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Loss utils (UNCHANGED) + weighted MSE\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)\n",
        "    se = (x_hat - x) ** 2\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean(), effK.detach()\n",
        "\n",
        "\n",
        "def weighted_mse(pred, target, weight, eps=1e-6):\n",
        "    w = torch.clamp(weight, min=0.0)\n",
        "    num = (w * (pred - target) ** 2).sum()\n",
        "    den = w.sum() + eps\n",
        "    return num / den\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7) Train (ONLY CHANGE: weighted loss_rate)\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "    stats = {k: 0.0 for k in [\n",
        "        'loss', 'loss_rate', 'loss_recon', 'loss_smooth', 'loss_phase_ent', 'loss_effk',\n",
        "        'mae_count'\n",
        "    ]}\n",
        "\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.005)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        y_count = batch[\"count\"].to(device)\n",
        "        length = batch[\"length\"].to(device)\n",
        "        w = batch[\"weight\"].to(device)  # ✅ window energy weight\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)\n",
        "        y_rate = y_count / duration\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rate_hat, z, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = weighted_mse(rate_hat, y_rate, w)  # ✅ only modification\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk, _ = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        count_hat = rate_hat * duration\n",
        "        stats['loss'] += loss.item()\n",
        "        stats['loss_rate'] += loss_rate.item()\n",
        "        stats['loss_recon'] += loss_recon.item()\n",
        "        stats['loss_smooth'] += loss_smooth.item()\n",
        "        stats['loss_phase_ent'] += loss_phase_ent.item()\n",
        "        stats['loss_effk'] += loss_effk.item()\n",
        "        stats['mae_count'] += torch.abs(count_hat - y_count).mean().item()\n",
        "\n",
        "    n = len(loader)\n",
        "    return {k: v / n for k, v in stats.items()}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8) Main: run ALL activities\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            6: 'Waist bends forward',\n",
        "            7: 'Frontal elevation of arms',\n",
        "            8: 'Knees bending',\n",
        "            10: 'Jogging',\n",
        "            12: 'Jump front & back'\n",
        "        },\n",
        "\n",
        "        # same sensor set for all activities (as you provided earlier)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            6: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            7: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            8: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            10: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            12: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        # GT counts\n",
        "        \"COUNT_TABLE\": {\n",
        "            6: {\n",
        "                \"subject1\": 21, \"subject2\": 19, \"subject3\": 21, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 21, \"subject9\": 21, \"subject10\": 20,\n",
        "            },\n",
        "            7: {\n",
        "                \"subject1\": 20, \"subject2\": 20, \"subject3\": 20, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 19, \"subject9\": 19, \"subject10\": 20,\n",
        "            },\n",
        "            8: {\n",
        "                \"subject1\": 20, \"subject2\": 21, \"subject3\": 21, \"subject4\": 19, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 21, \"subject8\": 21, \"subject9\": 21, \"subject10\": 21,\n",
        "            },\n",
        "            10: {\n",
        "                \"subject1\": 157, \"subject2\": 161, \"subject3\": 154, \"subject4\": 154, \"subject5\": 160,\n",
        "                \"subject6\": 156, \"subject7\": 153, \"subject8\": 160, \"subject9\": 166, \"subject10\": 156,\n",
        "            },\n",
        "            12: {\n",
        "                \"subject1\": 20, \"subject2\": 22, \"subject3\": 21, \"subject4\": 21, \"subject5\": 20,\n",
        "                \"subject6\": 21, \"subject7\": 19, \"subject8\": 20, \"subject9\": 20, \"subject10\": 20,\n",
        "            },\n",
        "        },\n",
        "\n",
        "        # Training params\n",
        "        \"epochs\": 100,\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "        \"fs\": 50,\n",
        "\n",
        "        # Windowing\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        # TrivialWeight hyper (no tuning)\n",
        "        \"energy_clip\": (0.0, 1.0),\n",
        "        \"energy_eps\": 1e-6,\n",
        "\n",
        "        # Model\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        # Temperature\n",
        "        \"tau\": 1.0,\n",
        "\n",
        "        # Loss weights\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "    }\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # Load all activities once\n",
        "    full_data = load_mhealth_dataset(CONFIG[\"data_dir\"], CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"COLUMN_NAMES\"])\n",
        "    if not full_data:\n",
        "        return\n",
        "\n",
        "    subjects = [f\"subject{i}\" for i in range(1, 11)]\n",
        "    act_ids = [6, 7, 8, 10, 12]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"TrivialWeight (Energy) vs Constant-rate label noise check — LOSO for ALL activities\")\n",
        "    print(\"TRAIN: energy-weighted window proxy | TEST: windowing inference (same)\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "    all_summary = {}\n",
        "\n",
        "    for act_id in act_ids:\n",
        "        act_name = CONFIG[\"TARGET_ACTIVITIES_MAP\"][act_id]\n",
        "        print(\"\\n\" + \"-\" * 110)\n",
        "        print(f\"[Activity {act_id}] {act_name}\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "        # Build labels for this activity\n",
        "        labels = []\n",
        "        for s in subjects:\n",
        "            if s in CONFIG[\"COUNT_TABLE\"][act_id]:\n",
        "                labels.append((s, act_id, CONFIG[\"COUNT_TABLE\"][act_id][s]))\n",
        "\n",
        "        loso_maes = []\n",
        "\n",
        "        for fold_idx, test_subj in enumerate(subjects):\n",
        "            set_strict_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            train_labels = [x for x in labels if x[0] != test_subj]\n",
        "            test_labels  = [x for x in labels if x[0] == test_subj]\n",
        "\n",
        "            train_trials = prepare_trial_list(train_labels, full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "            test_trials  = prepare_trial_list(test_labels,  full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "\n",
        "            if not test_trials:\n",
        "                print(f\"[Skip] Fold {fold_idx+1}: {test_subj} has no data.\")\n",
        "                continue\n",
        "\n",
        "            train_data = trial_list_to_windows(\n",
        "                train_trials,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                drop_last=CONFIG[\"drop_last\"],\n",
        "                energy_clip=CONFIG[\"energy_clip\"],\n",
        "                energy_eps=CONFIG[\"energy_eps\"],\n",
        "            )\n",
        "            test_data = test_trials\n",
        "\n",
        "            g = torch.Generator()\n",
        "            g.manual_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                TrialDataset(train_data),\n",
        "                batch_size=CONFIG[\"batch_size\"],\n",
        "                shuffle=True,\n",
        "                collate_fn=collate_variable_length,\n",
        "                generator=g,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            input_ch = train_data[0][\"data\"].shape[1]\n",
        "            model = KAutoCountModel(\n",
        "                input_ch=input_ch,\n",
        "                hidden_dim=CONFIG[\"hidden_dim\"],\n",
        "                latent_dim=CONFIG[\"latent_dim\"],\n",
        "                K_max=CONFIG[\"K_max\"]\n",
        "            ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "            for _ in range(CONFIG[\"epochs\"]):\n",
        "                _ = train_one_epoch(model, train_loader, optimizer, CONFIG, device)\n",
        "                scheduler.step()\n",
        "\n",
        "            # ---- fold test ----\n",
        "            model.eval()\n",
        "            fold_mae = 0.0\n",
        "            fold_str = \"\"\n",
        "\n",
        "            for item in test_data:\n",
        "                x_np = item[\"data\"]\n",
        "                pred_count, _ = predict_count_by_windowing(\n",
        "                    model,\n",
        "                    x_np=x_np,\n",
        "                    fs=CONFIG[\"fs\"],\n",
        "                    win_sec=CONFIG[\"win_sec\"],\n",
        "                    stride_sec=CONFIG[\"stride_sec\"],\n",
        "                    device=device,\n",
        "                    tau=CONFIG.get(\"tau\", 1.0),\n",
        "                    batch_size=CONFIG.get(\"batch_size\", 64)\n",
        "                )\n",
        "                gt_count = float(item[\"count\"])\n",
        "                fold_mae += abs(pred_count - gt_count)\n",
        "                fold_str += f\"[Pred(win): {pred_count:.1f} / GT: {gt_count:.0f}]\"\n",
        "\n",
        "            fold_mae /= len(test_data)\n",
        "            loso_maes.append(fold_mae)\n",
        "            print(f\"Fold {fold_idx+1:2d} | Test: {test_subj} | MAE: {fold_mae:.2f} | {fold_str}\")\n",
        "\n",
        "        mean_mae = float(np.mean(loso_maes)) if len(loso_maes) > 0 else float(\"nan\")\n",
        "        std_mae  = float(np.std(loso_maes))  if len(loso_maes) > 0 else float(\"nan\")\n",
        "        all_summary[act_id] = (mean_mae, std_mae)\n",
        "\n",
        "        print(\"-\" * 110)\n",
        "        print(f\"[Activity {act_id}] Final LOSO MAE: {mean_mae:.3f} ± {std_mae:.3f} (n_folds={len(loso_maes)})\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"Summary (per-activity LOSO MAE mean±std)\")\n",
        "    print(\"=\" * 110)\n",
        "    for act_id in act_ids:\n",
        "        m, s = all_summary.get(act_id, (float(\"nan\"), float(\"nan\")))\n",
        "        print(f\"  - act {act_id:2d} ({CONFIG['TARGET_ACTIVITIES_MAP'][act_id]}): {m:.3f} ± {s:.3f}\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NNlzMqtTtwf",
        "outputId": "e312080f-0f53-424a-c022-fdfea13c1c2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loading 10 subjects from /content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET...\n",
            "\n",
            "==============================================================================================================\n",
            "TrivialWeight (Energy) vs Constant-rate label noise check — LOSO for ALL activities\n",
            "TRAIN: energy-weighted window proxy | TEST: windowing inference (same)\n",
            "==============================================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 6] Waist bends forward\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 1.43 | [Pred(win): 19.6 / GT: 21]\n",
            "Fold  2 | Test: subject2 | MAE: 6.37 | [Pred(win): 25.4 / GT: 19]\n",
            "Fold  3 | Test: subject3 | MAE: 6.50 | [Pred(win): 27.5 / GT: 21]\n",
            "Fold  4 | Test: subject4 | MAE: 2.45 | [Pred(win): 22.4 / GT: 20]\n",
            "Fold  5 | Test: subject5 | MAE: 5.71 | [Pred(win): 25.7 / GT: 20]\n",
            "Fold  6 | Test: subject6 | MAE: 6.26 | [Pred(win): 13.7 / GT: 20]\n",
            "Fold  7 | Test: subject7 | MAE: 5.80 | [Pred(win): 25.8 / GT: 20]\n",
            "Fold  8 | Test: subject8 | MAE: 5.60 | [Pred(win): 15.4 / GT: 21]\n",
            "Fold  9 | Test: subject9 | MAE: 11.67 | [Pred(win): 32.7 / GT: 21]\n",
            "Fold 10 | Test: subject10 | MAE: 0.75 | [Pred(win): 19.3 / GT: 20]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 6] Final LOSO MAE: 5.253 ± 2.973 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 7] Frontal elevation of arms\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 0.11 | [Pred(win): 19.9 / GT: 20]\n",
            "Fold  2 | Test: subject2 | MAE: 2.65 | [Pred(win): 22.6 / GT: 20]\n",
            "Fold  3 | Test: subject3 | MAE: 4.12 | [Pred(win): 24.1 / GT: 20]\n",
            "Fold  4 | Test: subject4 | MAE: 1.60 | [Pred(win): 21.6 / GT: 20]\n",
            "Fold  5 | Test: subject5 | MAE: 1.52 | [Pred(win): 18.5 / GT: 20]\n",
            "Fold  6 | Test: subject6 | MAE: 7.20 | [Pred(win): 12.8 / GT: 20]\n",
            "Fold  7 | Test: subject7 | MAE: 1.63 | [Pred(win): 18.4 / GT: 20]\n",
            "Fold  8 | Test: subject8 | MAE: 2.02 | [Pred(win): 21.0 / GT: 19]\n",
            "Fold  9 | Test: subject9 | MAE: 1.41 | [Pred(win): 20.4 / GT: 19]\n",
            "Fold 10 | Test: subject10 | MAE: 0.99 | [Pred(win): 19.0 / GT: 20]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 7] Final LOSO MAE: 2.326 ± 1.908 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 8] Knees bending\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 12.25 | [Pred(win): 32.3 / GT: 20]\n",
            "Fold  2 | Test: subject2 | MAE: 1.54 | [Pred(win): 22.5 / GT: 21]\n",
            "Fold  3 | Test: subject3 | MAE: 4.94 | [Pred(win): 16.1 / GT: 21]\n",
            "Fold  4 | Test: subject4 | MAE: 5.66 | [Pred(win): 24.7 / GT: 19]\n",
            "Fold  5 | Test: subject5 | MAE: 1.35 | [Pred(win): 18.7 / GT: 20]\n",
            "Fold  6 | Test: subject6 | MAE: 4.88 | [Pred(win): 15.1 / GT: 20]\n",
            "Fold  7 | Test: subject7 | MAE: 2.24 | [Pred(win): 18.8 / GT: 21]\n",
            "Fold  8 | Test: subject8 | MAE: 3.26 | [Pred(win): 17.7 / GT: 21]\n",
            "Fold  9 | Test: subject9 | MAE: 4.39 | [Pred(win): 25.4 / GT: 21]\n",
            "Fold 10 | Test: subject10 | MAE: 2.36 | [Pred(win): 18.6 / GT: 21]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 8] Final LOSO MAE: 4.287 ± 3.021 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 10] Jogging\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 3.21 | [Pred(win): 153.8 / GT: 157]\n",
            "Fold  2 | Test: subject2 | MAE: 7.76 | [Pred(win): 168.8 / GT: 161]\n",
            "Fold  3 | Test: subject3 | MAE: 6.62 | [Pred(win): 147.4 / GT: 154]\n",
            "Fold  4 | Test: subject4 | MAE: 4.23 | [Pred(win): 158.2 / GT: 154]\n",
            "Fold  5 | Test: subject5 | MAE: 2.68 | [Pred(win): 157.3 / GT: 160]\n",
            "Fold  6 | Test: subject6 | MAE: 41.44 | [Pred(win): 197.4 / GT: 156]\n",
            "Fold  7 | Test: subject7 | MAE: 11.83 | [Pred(win): 141.2 / GT: 153]\n",
            "Fold  8 | Test: subject8 | MAE: 13.99 | [Pred(win): 146.0 / GT: 160]\n",
            "Fold  9 | Test: subject9 | MAE: 8.17 | [Pred(win): 174.2 / GT: 166]\n",
            "Fold 10 | Test: subject10 | MAE: 7.74 | [Pred(win): 163.7 / GT: 156]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 10] Final LOSO MAE: 10.767 ± 10.769 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 12] Jump front & back\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 0.43 | [Pred(win): 20.4 / GT: 20]\n",
            "Fold  2 | Test: subject2 | MAE: 0.29 | [Pred(win): 22.3 / GT: 22]\n",
            "Fold  3 | Test: subject3 | MAE: 0.33 | [Pred(win): 20.7 / GT: 21]\n",
            "Fold  4 | Test: subject4 | MAE: 2.05 | [Pred(win): 23.1 / GT: 21]\n",
            "Fold  5 | Test: subject5 | MAE: 3.52 | [Pred(win): 16.5 / GT: 20]\n",
            "Fold  6 | Test: subject6 | MAE: 0.24 | [Pred(win): 21.2 / GT: 21]\n",
            "Fold  7 | Test: subject7 | MAE: 0.58 | [Pred(win): 18.4 / GT: 19]\n",
            "Fold  8 | Test: subject8 | MAE: 0.00 | [Pred(win): 20.0 / GT: 20]\n",
            "Fold  9 | Test: subject9 | MAE: 1.29 | [Pred(win): 18.7 / GT: 20]\n",
            "Fold 10 | Test: subject10 | MAE: 2.01 | [Pred(win): 22.0 / GT: 20]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 12] Final LOSO MAE: 1.076 ± 1.072 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================================================================================================\n",
            "Summary (per-activity LOSO MAE mean±std)\n",
            "==============================================================================================================\n",
            "  - act  6 (Waist bends forward): 5.253 ± 2.973\n",
            "  - act  7 (Frontal elevation of arms): 2.326 ± 1.908\n",
            "  - act  8 (Knees bending): 4.287 ± 3.021\n",
            "  - act 10 (Jogging): 10.767 ± 10.769\n",
            "  - act 12 (Jump front & back): 1.076 ± 1.072\n",
            "==============================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TrivialWeight (Energy-based) Window Supervision for Count-only K-auto\n",
        "# ✅ Runs ALL activities: {6,7,8,10,12}\n",
        "# - Core model/logic unchanged\n",
        "# - Only change vs Constant-rate baseline:\n",
        "#     TRAIN loss_rate = weighted MSE using per-window energy weight\n",
        "# - TEST stays identical (windowing inference)\n",
        "# - Output: per-activity LOSO MAE mean±std + per-fold logs\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Loading {len(file_list)} subjects from {data_dir}...\")\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "def prepare_trial_list(label_config, full_data, target_map, feature_map):\n",
        "    trial_list = []\n",
        "    for subj, act_id, gt_count in label_config:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if subj in full_data and act_name in full_data[subj]:\n",
        "            raw_df = full_data[subj][act_name][feats]\n",
        "            raw_np = raw_df.values.astype(np.float32)\n",
        "\n",
        "            # per-trial z-score normalization (same as your reference)\n",
        "            mean = raw_np.mean(axis=0)\n",
        "            std = raw_np.std(axis=0) + 1e-6\n",
        "            norm_np = (raw_np - mean) / std\n",
        "\n",
        "            trial_list.append({\n",
        "                \"data\": norm_np,              # (T,C)\n",
        "                \"count\": float(gt_count),     # trial total count\n",
        "                \"meta\": f\"{subj}_{act_name}\"\n",
        "            })\n",
        "        else:\n",
        "            print(f\"[Skip] Missing data for {subj} - {act_name}\")\n",
        "\n",
        "    return trial_list\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Windowing + TrivialWeight\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True,\n",
        "                          energy_clip=(0.0, 1.0), energy_eps=1e-6):\n",
        "    \"\"\"\n",
        "    TRAIN only:\n",
        "      - window label from trial-average rate (constant proxy)\n",
        "      - weight from window energy proxy (trivial weighting)\n",
        "        w_i = clip(E_i / median(E_trial), 0..1)\n",
        "        E_i = mean(x^2) on normalized window signal\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C) normalized\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        # window slices\n",
        "        if T < win_len:\n",
        "            slices = [(0, T)]\n",
        "        else:\n",
        "            last_start = T - win_len\n",
        "            starts = list(range(0, last_start + 1, stride))\n",
        "            slices = [(st, st + win_len) for st in starts]\n",
        "            if not drop_last:\n",
        "                last_st = starts[-1] + stride\n",
        "                if last_st < T:\n",
        "                    slices.append((last_st, T))\n",
        "\n",
        "        # energies per window\n",
        "        energies = []\n",
        "        for (st, ed) in slices:\n",
        "            xw = x[st:ed]\n",
        "            Ew = float(np.mean(xw * xw))\n",
        "            energies.append(Ew)\n",
        "        energies = np.asarray(energies, dtype=np.float32)\n",
        "\n",
        "        med = float(np.median(energies)) if energies.size > 0 else 0.0\n",
        "        denom = max(med, energy_eps)\n",
        "        w = energies / denom\n",
        "        w = np.clip(w, energy_clip[0], energy_clip[1]).astype(np.float32)\n",
        "\n",
        "        # pack\n",
        "        for idx, (st, ed) in enumerate(slices):\n",
        "            win_dur = (ed - st) / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,   # proxy count label (same as constant-rate)\n",
        "                \"weight\": float(w[idx]),         # ✅ trivial weight\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "                \"parent_meta\": meta,\n",
        "                \"parent_T\": T,\n",
        "                \"win_start\": st,\n",
        "                \"win_end\": ed,\n",
        "            })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    \"\"\"\n",
        "    TEST only: identical to your reference\n",
        "      trial -> windows -> avg rate -> total count\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        pred_count = float(rate_hat.item() * total_dur)\n",
        "        return pred_count, np.array([float(rate_hat.item())], dtype=np.float32)\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N,win_len,C)\n",
        "\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N,C,win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count), rates\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Dataset / Collate\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item[\"data\"], dtype=torch.float32).transpose(0, 1)  # (C,T)\n",
        "        count = torch.tensor(item[\"count\"], dtype=torch.float32)\n",
        "        weight = torch.tensor(item.get(\"weight\", 1.0), dtype=torch.float32)\n",
        "        return data, count, weight, item[\"meta\"]\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, weights, metas, lengths = [], [], [], [], [], []\n",
        "    for data, count, w, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        weights.append(w)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),           # (B,C,Tmax)\n",
        "        \"mask\": torch.stack(masks),                 # (B,Tmax)\n",
        "        \"count\": torch.stack(counts),               # (B,)\n",
        "        \"weight\": torch.stack(weights),             # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Model (UNCHANGED)\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        z = z.transpose(1, 2)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)\n",
        "        x_hat = self.net(zt)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)\n",
        "        amp = F.softplus(out[..., 0])\n",
        "        phase_logits = out[..., 1:]\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1)\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6, k_hidden=64):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "\n",
        "        amp_t, phase_p, phase_logits = self.rate_head(z, tau=tau)\n",
        "        micro_rate_t = amp_t\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"phase_p\": phase_p,\n",
        "            \"phase_logits\": phase_logits,\n",
        "            \"micro_rate_t\": micro_rate_t,\n",
        "            \"rep_rate_t\": rep_rate_t,\n",
        "            \"k_hat\": k_hat,\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Loss utils (UNCHANGED) + weighted MSE\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)\n",
        "    se = (x_hat - x) ** 2\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean(), effK.detach()\n",
        "\n",
        "\n",
        "def weighted_mse(pred, target, weight, eps=1e-6):\n",
        "    w = torch.clamp(weight, min=0.0)\n",
        "    num = (w * (pred - target) ** 2).sum()\n",
        "    den = w.sum() + eps\n",
        "    return num / den\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7) Train (ONLY CHANGE: weighted loss_rate)\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "    stats = {k: 0.0 for k in [\n",
        "        'loss', 'loss_rate', 'loss_recon', 'loss_smooth', 'loss_phase_ent', 'loss_effk',\n",
        "        'mae_count'\n",
        "    ]}\n",
        "\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.005)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        y_count = batch[\"count\"].to(device)\n",
        "        length = batch[\"length\"].to(device)\n",
        "        w = batch[\"weight\"].to(device)  # ✅ window energy weight\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)\n",
        "        y_rate = y_count / duration\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rate_hat, z, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = weighted_mse(rate_hat, y_rate, w)  # ✅ only modification\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk, _ = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        count_hat = rate_hat * duration\n",
        "        stats['loss'] += loss.item()\n",
        "        stats['loss_rate'] += loss_rate.item()\n",
        "        stats['loss_recon'] += loss_recon.item()\n",
        "        stats['loss_smooth'] += loss_smooth.item()\n",
        "        stats['loss_phase_ent'] += loss_phase_ent.item()\n",
        "        stats['loss_effk'] += loss_effk.item()\n",
        "        stats['mae_count'] += torch.abs(count_hat - y_count).mean().item()\n",
        "\n",
        "    n = len(loader)\n",
        "    return {k: v / n for k, v in stats.items()}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8) Main: run ALL activities\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            11: 'Running'\n",
        "        },\n",
        "\n",
        "        # same sensor set for all activities (as you provided earlier)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            11: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        # GT counts\n",
        "        \"COUNT_TABLE\": {\n",
        "            11: {\n",
        "                \"subject1\": 165, \"subject2\": 158, \"subject3\": 174, \"subject4\": 163, \"subject5\": 157,\n",
        "                \"subject6\": 172, \"subject7\": 149, \"subject8\": 166, \"subject9\": 174, \"subject10\": 172,\n",
        "            },\n",
        "        },\n",
        "\n",
        "        # Training params\n",
        "        \"epochs\": 100,\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "        \"fs\": 50,\n",
        "\n",
        "        # Windowing\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        # TrivialWeight hyper (no tuning)\n",
        "        \"energy_clip\": (0.0, 1.0),\n",
        "        \"energy_eps\": 1e-6,\n",
        "\n",
        "        # Model\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        # Temperature\n",
        "        \"tau\": 1.0,\n",
        "\n",
        "        # Loss weights\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "    }\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # Load all activities once\n",
        "    full_data = load_mhealth_dataset(CONFIG[\"data_dir\"], CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"COLUMN_NAMES\"])\n",
        "    if not full_data:\n",
        "        return\n",
        "\n",
        "    subjects = [f\"subject{i}\" for i in range(1, 11)]\n",
        "    act_ids = [11]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"TrivialWeight (Energy) vs Constant-rate label noise check — LOSO for ALL activities\")\n",
        "    print(\"TRAIN: energy-weighted window proxy | TEST: windowing inference (same)\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "    all_summary = {}\n",
        "\n",
        "    for act_id in act_ids:\n",
        "        act_name = CONFIG[\"TARGET_ACTIVITIES_MAP\"][act_id]\n",
        "        print(\"\\n\" + \"-\" * 110)\n",
        "        print(f\"[Activity {act_id}] {act_name}\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "        # Build labels for this activity\n",
        "        labels = []\n",
        "        for s in subjects:\n",
        "            if s in CONFIG[\"COUNT_TABLE\"][act_id]:\n",
        "                labels.append((s, act_id, CONFIG[\"COUNT_TABLE\"][act_id][s]))\n",
        "\n",
        "        loso_maes = []\n",
        "\n",
        "        for fold_idx, test_subj in enumerate(subjects):\n",
        "            set_strict_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            train_labels = [x for x in labels if x[0] != test_subj]\n",
        "            test_labels  = [x for x in labels if x[0] == test_subj]\n",
        "\n",
        "            train_trials = prepare_trial_list(train_labels, full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "            test_trials  = prepare_trial_list(test_labels,  full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "\n",
        "            if not test_trials:\n",
        "                print(f\"[Skip] Fold {fold_idx+1}: {test_subj} has no data.\")\n",
        "                continue\n",
        "\n",
        "            train_data = trial_list_to_windows(\n",
        "                train_trials,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                drop_last=CONFIG[\"drop_last\"],\n",
        "                energy_clip=CONFIG[\"energy_clip\"],\n",
        "                energy_eps=CONFIG[\"energy_eps\"],\n",
        "            )\n",
        "            test_data = test_trials\n",
        "\n",
        "            g = torch.Generator()\n",
        "            g.manual_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                TrialDataset(train_data),\n",
        "                batch_size=CONFIG[\"batch_size\"],\n",
        "                shuffle=True,\n",
        "                collate_fn=collate_variable_length,\n",
        "                generator=g,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            input_ch = train_data[0][\"data\"].shape[1]\n",
        "            model = KAutoCountModel(\n",
        "                input_ch=input_ch,\n",
        "                hidden_dim=CONFIG[\"hidden_dim\"],\n",
        "                latent_dim=CONFIG[\"latent_dim\"],\n",
        "                K_max=CONFIG[\"K_max\"]\n",
        "            ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "            for _ in range(CONFIG[\"epochs\"]):\n",
        "                _ = train_one_epoch(model, train_loader, optimizer, CONFIG, device)\n",
        "                scheduler.step()\n",
        "\n",
        "            # ---- fold test ----\n",
        "            model.eval()\n",
        "            fold_mae = 0.0\n",
        "            fold_str = \"\"\n",
        "\n",
        "            for item in test_data:\n",
        "                x_np = item[\"data\"]\n",
        "                pred_count, _ = predict_count_by_windowing(\n",
        "                    model,\n",
        "                    x_np=x_np,\n",
        "                    fs=CONFIG[\"fs\"],\n",
        "                    win_sec=CONFIG[\"win_sec\"],\n",
        "                    stride_sec=CONFIG[\"stride_sec\"],\n",
        "                    device=device,\n",
        "                    tau=CONFIG.get(\"tau\", 1.0),\n",
        "                    batch_size=CONFIG.get(\"batch_size\", 64)\n",
        "                )\n",
        "                gt_count = float(item[\"count\"])\n",
        "                fold_mae += abs(pred_count - gt_count)\n",
        "                fold_str += f\"[Pred(win): {pred_count:.1f} / GT: {gt_count:.0f}]\"\n",
        "\n",
        "            fold_mae /= len(test_data)\n",
        "            loso_maes.append(fold_mae)\n",
        "            print(f\"Fold {fold_idx+1:2d} | Test: {test_subj} | MAE: {fold_mae:.2f} | {fold_str}\")\n",
        "\n",
        "        mean_mae = float(np.mean(loso_maes)) if len(loso_maes) > 0 else float(\"nan\")\n",
        "        std_mae  = float(np.std(loso_maes))  if len(loso_maes) > 0 else float(\"nan\")\n",
        "        all_summary[act_id] = (mean_mae, std_mae)\n",
        "\n",
        "        print(\"-\" * 110)\n",
        "        print(f\"[Activity {act_id}] Final LOSO MAE: {mean_mae:.3f} ± {std_mae:.3f} (n_folds={len(loso_maes)})\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"Summary (per-activity LOSO MAE mean±std)\")\n",
        "    print(\"=\" * 110)\n",
        "    for act_id in act_ids:\n",
        "        m, s = all_summary.get(act_id, (float(\"nan\"), float(\"nan\")))\n",
        "        print(f\"  - act {act_id:2d} ({CONFIG['TARGET_ACTIVITIES_MAP'][act_id]}): {m:.3f} ± {s:.3f}\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_MdhnmfXGaD",
        "outputId": "4b2d8a33-f7c4-4b5d-f28b-2f54789cfa18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loading 10 subjects from /content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET...\n",
            "\n",
            "==============================================================================================================\n",
            "TrivialWeight (Energy) vs Constant-rate label noise check — LOSO for ALL activities\n",
            "TRAIN: energy-weighted window proxy | TEST: windowing inference (same)\n",
            "==============================================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 11] Running\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Fold  1 | Test: subject1 | MAE: 2.88 | [Pred(win): 162.1 / GT: 165]\n",
            "Fold  2 | Test: subject2 | MAE: 14.50 | [Pred(win): 172.5 / GT: 158]\n",
            "Fold  3 | Test: subject3 | MAE: 21.54 | [Pred(win): 152.5 / GT: 174]\n",
            "Fold  4 | Test: subject4 | MAE: 19.60 | [Pred(win): 182.6 / GT: 163]\n",
            "Fold  5 | Test: subject5 | MAE: 1.47 | [Pred(win): 158.5 / GT: 157]\n",
            "Fold  6 | Test: subject6 | MAE: 24.23 | [Pred(win): 147.8 / GT: 172]\n",
            "Fold  7 | Test: subject7 | MAE: 16.47 | [Pred(win): 165.5 / GT: 149]\n",
            "Fold  8 | Test: subject8 | MAE: 11.57 | [Pred(win): 154.4 / GT: 166]\n",
            "Fold  9 | Test: subject9 | MAE: 17.00 | [Pred(win): 191.0 / GT: 174]\n",
            "Fold 10 | Test: subject10 | MAE: 21.88 | [Pred(win): 150.1 / GT: 172]\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "[Activity 11] Final LOSO MAE: 15.114 ± 7.378 (n_folds=10)\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================================================================================================\n",
            "Summary (per-activity LOSO MAE mean±std)\n",
            "==============================================================================================================\n",
            "  - act 11 (Running): 15.114 ± 7.378\n",
            "==============================================================================================================\n"
          ]
        }
      ]
    }
  ]
}